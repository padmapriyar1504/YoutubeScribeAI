{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4fcab6ab122c4cee9cad374995460022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_917f8b2a28ac44079d4387e00688d63c",
              "IPY_MODEL_fa60595bb47f4803ad0f0678c510961e",
              "IPY_MODEL_acc41e0c9718469aa9ece362c8901a16"
            ],
            "layout": "IPY_MODEL_a3f3e23470b44844bab105c9bcc4f26d"
          }
        },
        "917f8b2a28ac44079d4387e00688d63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5066f0725c0a4aacb9f2e98e97ed81df",
            "placeholder": "​",
            "style": "IPY_MODEL_b4fa4c1e5af6442db0415b872befd5eb",
            "value": "modules.json: 100%"
          }
        },
        "fa60595bb47f4803ad0f0678c510961e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1d90375d1e545078146680bc91431e2",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc4d08234ef54857b8a7ecc2970c329f",
            "value": 349
          }
        },
        "acc41e0c9718469aa9ece362c8901a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60aabf5ea0484c01a2be35175546ee72",
            "placeholder": "​",
            "style": "IPY_MODEL_1650684691ef46b4a2ee644ebd237f3b",
            "value": " 349/349 [00:00&lt;00:00, 14.6kB/s]"
          }
        },
        "a3f3e23470b44844bab105c9bcc4f26d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5066f0725c0a4aacb9f2e98e97ed81df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fa4c1e5af6442db0415b872befd5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1d90375d1e545078146680bc91431e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4d08234ef54857b8a7ecc2970c329f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60aabf5ea0484c01a2be35175546ee72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1650684691ef46b4a2ee644ebd237f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea406fe3e4240c3894978ac673b6353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a65279a25854538828619643c420719",
              "IPY_MODEL_e901bf3a82cb4b0c81c5a152136b5aaa",
              "IPY_MODEL_cf934b1737804f5ea258e19e8f38b19a"
            ],
            "layout": "IPY_MODEL_901c282d69dc48c58749b0f332ac4a2f"
          }
        },
        "1a65279a25854538828619643c420719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d52a270c7cb424cb37395c4b9f8f821",
            "placeholder": "​",
            "style": "IPY_MODEL_4a274ea8289b40469dfc9caac66c56f2",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "e901bf3a82cb4b0c81c5a152136b5aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4d45027d3974c6ab3eb8c0de315d7f8",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d7a0d91250a48fc88f53700c7418a7e",
            "value": 116
          }
        },
        "cf934b1737804f5ea258e19e8f38b19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2eeaad500a34213a0d541f26e74b4c0",
            "placeholder": "​",
            "style": "IPY_MODEL_650547cf756e4fc9bcb361bd27acd2af",
            "value": " 116/116 [00:00&lt;00:00, 6.29kB/s]"
          }
        },
        "901c282d69dc48c58749b0f332ac4a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d52a270c7cb424cb37395c4b9f8f821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a274ea8289b40469dfc9caac66c56f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4d45027d3974c6ab3eb8c0de315d7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7a0d91250a48fc88f53700c7418a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2eeaad500a34213a0d541f26e74b4c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650547cf756e4fc9bcb361bd27acd2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1075f63c7dca49d3bb1777e933f88dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93c5027ce2b747e38e022aea5facef9e",
              "IPY_MODEL_c5f0fa2c6d29419e8c2ba5d46a33463c",
              "IPY_MODEL_1cab80038c774e3b8a8e5a881e79d5f5"
            ],
            "layout": "IPY_MODEL_ce973dd5f7714fd693bf2b76f2a24092"
          }
        },
        "93c5027ce2b747e38e022aea5facef9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b4684a1e1e44769ac0afc87216554df",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b4df8cead448018df8ea3556a49876",
            "value": "README.md: 100%"
          }
        },
        "c5f0fa2c6d29419e8c2ba5d46a33463c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2dcdbb001ca416384210ac5fe64592a",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4642a22af27b48a5834921ba3ad58dd2",
            "value": 10659
          }
        },
        "1cab80038c774e3b8a8e5a881e79d5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f7ee41f5af644d89ef7635baa4cfa1e",
            "placeholder": "​",
            "style": "IPY_MODEL_2d515385903e491ca64dd97cc9b43968",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 607kB/s]"
          }
        },
        "ce973dd5f7714fd693bf2b76f2a24092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4684a1e1e44769ac0afc87216554df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b4df8cead448018df8ea3556a49876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2dcdbb001ca416384210ac5fe64592a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4642a22af27b48a5834921ba3ad58dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f7ee41f5af644d89ef7635baa4cfa1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d515385903e491ca64dd97cc9b43968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50f9b8dcdf0e4a3a9cf4900d94c83ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d159094afb9d4a43b54d189cb11e7d25",
              "IPY_MODEL_a6a4ec35ef574e598acd3d27035d6648",
              "IPY_MODEL_8ea6a979527f4f5e8eede26c1112c8d5"
            ],
            "layout": "IPY_MODEL_4d25bd6b12fc40c0b03df1d3f401f6d4"
          }
        },
        "d159094afb9d4a43b54d189cb11e7d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e793d9426b4716bcab02de2ba05ba4",
            "placeholder": "​",
            "style": "IPY_MODEL_129c2764533749518e77aa148ccdf54c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "a6a4ec35ef574e598acd3d27035d6648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b06686463ae74e0bb0db1048965420f3",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cd97f94133842c4881168290f7c57cb",
            "value": 53
          }
        },
        "8ea6a979527f4f5e8eede26c1112c8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7406a17bd414e45aec1ef5940b00e4f",
            "placeholder": "​",
            "style": "IPY_MODEL_6c2e25d6bdbd4351a3fccf6b4ac354e4",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.99kB/s]"
          }
        },
        "4d25bd6b12fc40c0b03df1d3f401f6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e793d9426b4716bcab02de2ba05ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "129c2764533749518e77aa148ccdf54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b06686463ae74e0bb0db1048965420f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd97f94133842c4881168290f7c57cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7406a17bd414e45aec1ef5940b00e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2e25d6bdbd4351a3fccf6b4ac354e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcc6d360bc174717874008835b19c9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bb84b352ccc44c5b7a532ec215646d6",
              "IPY_MODEL_77a42355edb2441fa11427dacb54543e",
              "IPY_MODEL_cf6cbc13cdb44cfe999f0e59bb4499f5"
            ],
            "layout": "IPY_MODEL_5b4b54783f1441f892ed8c2bbd2e7c2b"
          }
        },
        "8bb84b352ccc44c5b7a532ec215646d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f334a6768ba94b13814837a87ab92f47",
            "placeholder": "​",
            "style": "IPY_MODEL_2f94928bae21404da692f1f2bd12a16e",
            "value": "config.json: 100%"
          }
        },
        "77a42355edb2441fa11427dacb54543e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7acb680de194fcfaded99d6faf82175",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ed1dcf1aaa44384af28587593c755f6",
            "value": 612
          }
        },
        "cf6cbc13cdb44cfe999f0e59bb4499f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b7c13ef7764cf3a2579fb3da5d6645",
            "placeholder": "​",
            "style": "IPY_MODEL_7ccc9a6ad6e94ae0be453796e9512830",
            "value": " 612/612 [00:00&lt;00:00, 23.2kB/s]"
          }
        },
        "5b4b54783f1441f892ed8c2bbd2e7c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f334a6768ba94b13814837a87ab92f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f94928bae21404da692f1f2bd12a16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7acb680de194fcfaded99d6faf82175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed1dcf1aaa44384af28587593c755f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9b7c13ef7764cf3a2579fb3da5d6645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ccc9a6ad6e94ae0be453796e9512830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb0d0764af5404d936544ce4eed23d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_973ff65359164a16a382f8512df82040",
              "IPY_MODEL_2639f2bad946495aa1434c66acafc2f4",
              "IPY_MODEL_234c87b809844265889d0d611f1ca805"
            ],
            "layout": "IPY_MODEL_4b6623fa8d8949d1a30832bbf3c515a6"
          }
        },
        "973ff65359164a16a382f8512df82040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20126b56372d4c239769d977819c9f22",
            "placeholder": "​",
            "style": "IPY_MODEL_b0ba77817749459fa30db8090924e490",
            "value": "model.safetensors: 100%"
          }
        },
        "2639f2bad946495aa1434c66acafc2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f68c00d65b407a95b6ad19158b29c7",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fc210866ced45b882f4467418062a00",
            "value": 90868376
          }
        },
        "234c87b809844265889d0d611f1ca805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0fa8bc59d504ab0af858d22bd719417",
            "placeholder": "​",
            "style": "IPY_MODEL_d8d9f9a8e4ec4e9aa15ec4711464de4f",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 206MB/s]"
          }
        },
        "4b6623fa8d8949d1a30832bbf3c515a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20126b56372d4c239769d977819c9f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ba77817749459fa30db8090924e490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27f68c00d65b407a95b6ad19158b29c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc210866ced45b882f4467418062a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0fa8bc59d504ab0af858d22bd719417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d9f9a8e4ec4e9aa15ec4711464de4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5dceecdc1f840b795b591d455989600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_285ec321793d49ddb323cbcddd4a87bc",
              "IPY_MODEL_309a514ae6494013962fae419d78f6ef",
              "IPY_MODEL_564f96bd17be422fb4b321b934e69a6b"
            ],
            "layout": "IPY_MODEL_3b7fdf075e39432784421ba2826bc4ec"
          }
        },
        "285ec321793d49ddb323cbcddd4a87bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79bf21db6fe54bedbf4faee4baf0c16c",
            "placeholder": "​",
            "style": "IPY_MODEL_51a13b64753a40c69dda8ebe54247144",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "309a514ae6494013962fae419d78f6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf108f5b897436f99589bf9025c9f99",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a3ca3a6ced4da5b0f39491f58622ae",
            "value": 350
          }
        },
        "564f96bd17be422fb4b321b934e69a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd268b5343c34999b39ea232325bcd85",
            "placeholder": "​",
            "style": "IPY_MODEL_e02912630a514289a1ae347e3c94cd41",
            "value": " 350/350 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "3b7fdf075e39432784421ba2826bc4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79bf21db6fe54bedbf4faee4baf0c16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a13b64753a40c69dda8ebe54247144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf108f5b897436f99589bf9025c9f99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a3ca3a6ced4da5b0f39491f58622ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd268b5343c34999b39ea232325bcd85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02912630a514289a1ae347e3c94cd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb95848df464402a9dbdf66424f341a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80623a3d7aaa43b59a5cbfd8fa727656",
              "IPY_MODEL_5b6d8f485aac4ac799e20cb8bdf005ec",
              "IPY_MODEL_d11ff4f9c357480b932015f908a207a0"
            ],
            "layout": "IPY_MODEL_02f58273c357445f95931588500a49d8"
          }
        },
        "80623a3d7aaa43b59a5cbfd8fa727656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a1c71dd4f44ea5af44d17737aa7156",
            "placeholder": "​",
            "style": "IPY_MODEL_02308ab1898b4f7ba22b20d3654d9bca",
            "value": "vocab.txt: 100%"
          }
        },
        "5b6d8f485aac4ac799e20cb8bdf005ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce9b2d3740c4b1287bb4bf08e0b3568",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3961eb2137754e51bd3b23a3cfe8a0a0",
            "value": 231508
          }
        },
        "d11ff4f9c357480b932015f908a207a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70a04c499ba431ba13dc2cc7a989974",
            "placeholder": "​",
            "style": "IPY_MODEL_efe50dd91ae845478fabebdce3246e9e",
            "value": " 232k/232k [00:00&lt;00:00, 6.01MB/s]"
          }
        },
        "02f58273c357445f95931588500a49d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a1c71dd4f44ea5af44d17737aa7156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02308ab1898b4f7ba22b20d3654d9bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cce9b2d3740c4b1287bb4bf08e0b3568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3961eb2137754e51bd3b23a3cfe8a0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70a04c499ba431ba13dc2cc7a989974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe50dd91ae845478fabebdce3246e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3361a02509744f9bd279c56df1ded85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c88ad1e272874a72bd4e3cbf503d833e",
              "IPY_MODEL_130caa04affa4a98bfb6b066d9b8d1ab",
              "IPY_MODEL_291ec2a111f44ec885472bd56525995b"
            ],
            "layout": "IPY_MODEL_56e5217ae52d4a5ba6ba784bd2dd45d0"
          }
        },
        "c88ad1e272874a72bd4e3cbf503d833e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd22a2a7af524e05b71dcb6ad8905d85",
            "placeholder": "​",
            "style": "IPY_MODEL_ef488f291bb840fcab5c1bab95b5b451",
            "value": "tokenizer.json: 100%"
          }
        },
        "130caa04affa4a98bfb6b066d9b8d1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b4f2a8238594691876d3655f98ccb50",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0318bd3f144451c91d9a8623ed2a727",
            "value": 466247
          }
        },
        "291ec2a111f44ec885472bd56525995b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_939ce606f918479fad595d154196d8da",
            "placeholder": "​",
            "style": "IPY_MODEL_d482478294d04995a4282db976a103aa",
            "value": " 466k/466k [00:00&lt;00:00, 17.8MB/s]"
          }
        },
        "56e5217ae52d4a5ba6ba784bd2dd45d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd22a2a7af524e05b71dcb6ad8905d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef488f291bb840fcab5c1bab95b5b451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b4f2a8238594691876d3655f98ccb50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0318bd3f144451c91d9a8623ed2a727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "939ce606f918479fad595d154196d8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d482478294d04995a4282db976a103aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f21909005eb244cfbd3f0414851d6dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30c71d500a134c3a95d09f17c468bef6",
              "IPY_MODEL_e5d86fbcc42e4a74a210c4c6f111fa12",
              "IPY_MODEL_67546c8dd53248bab73e06ddb74cbc8f"
            ],
            "layout": "IPY_MODEL_024b20157d1d48d584e509113139ae43"
          }
        },
        "30c71d500a134c3a95d09f17c468bef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36bf13fefa04a67af39a5e69a4d8e3d",
            "placeholder": "​",
            "style": "IPY_MODEL_035e36198f4f446bb68af830e2897f17",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e5d86fbcc42e4a74a210c4c6f111fa12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f776fd5c153a4e79888446fdba49aeaa",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79692437fde04393828ea52eb74e3e6e",
            "value": 112
          }
        },
        "67546c8dd53248bab73e06ddb74cbc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b955914ac4b4b61a06998713cc4845e",
            "placeholder": "​",
            "style": "IPY_MODEL_3f2580ae7a824c87b6e408b880aba7cf",
            "value": " 112/112 [00:00&lt;00:00, 3.09kB/s]"
          }
        },
        "024b20157d1d48d584e509113139ae43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36bf13fefa04a67af39a5e69a4d8e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035e36198f4f446bb68af830e2897f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f776fd5c153a4e79888446fdba49aeaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79692437fde04393828ea52eb74e3e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b955914ac4b4b61a06998713cc4845e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2580ae7a824c87b6e408b880aba7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0a00b73ace544a2afb3746675253824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0df94fea681a4473bc91de42ae75c3c2",
              "IPY_MODEL_83b5b51e8ce743e9aa101336b63fc496",
              "IPY_MODEL_732cf5c4255f4f998856b13594360bce"
            ],
            "layout": "IPY_MODEL_403c9ed14003491e82999d7686e7cc57"
          }
        },
        "0df94fea681a4473bc91de42ae75c3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd130972affd47e4be57f8d6f552dced",
            "placeholder": "​",
            "style": "IPY_MODEL_3a90c25537344c10bc4ce6d957daaad7",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "83b5b51e8ce743e9aa101336b63fc496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9296a80244fb4b9f9f6fae3027c6a421",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e8efb512d844f08a001939b3428eef9",
            "value": 190
          }
        },
        "732cf5c4255f4f998856b13594360bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d94e23e6634cb09bec388df579d1f3",
            "placeholder": "​",
            "style": "IPY_MODEL_4f06310640df44c8a9b2a67c8abb976f",
            "value": " 190/190 [00:00&lt;00:00, 7.23kB/s]"
          }
        },
        "403c9ed14003491e82999d7686e7cc57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd130972affd47e4be57f8d6f552dced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a90c25537344c10bc4ce6d957daaad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9296a80244fb4b9f9f6fae3027c6a421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8efb512d844f08a001939b3428eef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10d94e23e6634cb09bec388df579d1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f06310640df44c8a9b2a67c8abb976f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f588edd33c5e49b6bf1d56d4e2ef6588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab87b72eebc841c1b39de8b0ded991de",
              "IPY_MODEL_04a4c16f0dd247969f2b163b401f45b7",
              "IPY_MODEL_8bdbc472081046c2925e1081200114ce"
            ],
            "layout": "IPY_MODEL_27d5940878c04be6bc17215bda97bf97"
          }
        },
        "ab87b72eebc841c1b39de8b0ded991de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857ce78359bf4d379774b064c1c250ef",
            "placeholder": "​",
            "style": "IPY_MODEL_4e6f932cddad4676ae937e225924468a",
            "value": "modules.json: 100%"
          }
        },
        "04a4c16f0dd247969f2b163b401f45b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae83d405f7e54c369d9e225ce7587d39",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f75a21ff6a248dfaf2535df57e184d2",
            "value": 349
          }
        },
        "8bdbc472081046c2925e1081200114ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1efa80263db04aef99fd6852e476dc11",
            "placeholder": "​",
            "style": "IPY_MODEL_c66280dde41f4fcc99c5982ec5c42655",
            "value": " 349/349 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "27d5940878c04be6bc17215bda97bf97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "857ce78359bf4d379774b064c1c250ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e6f932cddad4676ae937e225924468a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae83d405f7e54c369d9e225ce7587d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f75a21ff6a248dfaf2535df57e184d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1efa80263db04aef99fd6852e476dc11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66280dde41f4fcc99c5982ec5c42655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673677cbbfde40f3b087aad3d21eef14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_538c7118abf249919332577948409ef6",
              "IPY_MODEL_2c822c67003d45c0bd8842227a9fbec8",
              "IPY_MODEL_34d5c1aa0c5d4642a4127656987d6432"
            ],
            "layout": "IPY_MODEL_3dcc7372f6cd4d419e9b1fc30675f98f"
          }
        },
        "538c7118abf249919332577948409ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_631c60e528564a08bba06ea1e83157c9",
            "placeholder": "​",
            "style": "IPY_MODEL_01eb1735409b4571a6b034a08f59b905",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "2c822c67003d45c0bd8842227a9fbec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5a455c41784c7e96355acd2ce2a9b9",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a85c9364370740c0b0eb71911a7ae7ed",
            "value": 116
          }
        },
        "34d5c1aa0c5d4642a4127656987d6432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a79420448742c991879ee149cd0ab1",
            "placeholder": "​",
            "style": "IPY_MODEL_01176bc613f14134ae88f65c1af407d2",
            "value": " 116/116 [00:00&lt;00:00, 8.34kB/s]"
          }
        },
        "3dcc7372f6cd4d419e9b1fc30675f98f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631c60e528564a08bba06ea1e83157c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01eb1735409b4571a6b034a08f59b905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a5a455c41784c7e96355acd2ce2a9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85c9364370740c0b0eb71911a7ae7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12a79420448742c991879ee149cd0ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01176bc613f14134ae88f65c1af407d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ab7d6c936e4baab9480a01b22da05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08f4b57dbec543409ce33ec54d9ed8c1",
              "IPY_MODEL_5a09da14798543908720db8f48e714f2",
              "IPY_MODEL_998b7880e2b14420adce6744e0f20ea9"
            ],
            "layout": "IPY_MODEL_ab0ff017b75a4c95babf931a9b7c7d63"
          }
        },
        "08f4b57dbec543409ce33ec54d9ed8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd48e486705e4db680ed655295e5053f",
            "placeholder": "​",
            "style": "IPY_MODEL_474ad3ab9f444961849009424429451d",
            "value": "README.md: 100%"
          }
        },
        "5a09da14798543908720db8f48e714f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e3a80ef0c342f896eee88d22fa7441",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d9f8b08fe784c72aa49105d1ba15971",
            "value": 10659
          }
        },
        "998b7880e2b14420adce6744e0f20ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c116284bf134c3591df36b7d6506775",
            "placeholder": "​",
            "style": "IPY_MODEL_43ce4498d99943cd996898fddff77f4e",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 686kB/s]"
          }
        },
        "ab0ff017b75a4c95babf931a9b7c7d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd48e486705e4db680ed655295e5053f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474ad3ab9f444961849009424429451d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70e3a80ef0c342f896eee88d22fa7441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9f8b08fe784c72aa49105d1ba15971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c116284bf134c3591df36b7d6506775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ce4498d99943cd996898fddff77f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2fd7d1760ca4d6b9a21e37da9604720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_278bf424a7a24383af7cd06890412382",
              "IPY_MODEL_1afc47886c254ca193ac18d775f428e3",
              "IPY_MODEL_beccde9fa2f7492995df66c417cfa853"
            ],
            "layout": "IPY_MODEL_94f35e7a169d4ac2b2ccfa4a40a34482"
          }
        },
        "278bf424a7a24383af7cd06890412382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4557be61824696bbeb040ac5a46223",
            "placeholder": "​",
            "style": "IPY_MODEL_f9888d33ef424e58b04a8dbda1936756",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "1afc47886c254ca193ac18d775f428e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b6cc247b77480284b9a0829c880040",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3afadc89ad5643a0aa8b1e9c42e89cdc",
            "value": 53
          }
        },
        "beccde9fa2f7492995df66c417cfa853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_115230a817c44bc983fc298308ce282c",
            "placeholder": "​",
            "style": "IPY_MODEL_8120abcb54cf41a090fd2ba02c4d7aff",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.89kB/s]"
          }
        },
        "94f35e7a169d4ac2b2ccfa4a40a34482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4557be61824696bbeb040ac5a46223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9888d33ef424e58b04a8dbda1936756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1b6cc247b77480284b9a0829c880040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afadc89ad5643a0aa8b1e9c42e89cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "115230a817c44bc983fc298308ce282c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8120abcb54cf41a090fd2ba02c4d7aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d8b788c69044cd8b71e802df468880f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42e0639c01e240debc1d116e6b359a2c",
              "IPY_MODEL_5c7b36e005444df48cb474c37246c4cf",
              "IPY_MODEL_5ae5887fd7ea4d7383ea62d2b13b87cc"
            ],
            "layout": "IPY_MODEL_5ddb365990bc40f8882d3979652a8fae"
          }
        },
        "42e0639c01e240debc1d116e6b359a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7f6bf9ad614af7b4209c39183a34f7",
            "placeholder": "​",
            "style": "IPY_MODEL_83b9e9ba049a445695e4522479cf6a41",
            "value": "config.json: 100%"
          }
        },
        "5c7b36e005444df48cb474c37246c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_105ec57f66a34e51ab5d7e2fd5e35295",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c665f5317a34412ba05486046be03ff4",
            "value": 612
          }
        },
        "5ae5887fd7ea4d7383ea62d2b13b87cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae4f29a92aa0488386b23eaa0c8a7c73",
            "placeholder": "​",
            "style": "IPY_MODEL_3d8028c067fa4c4a9eda35661534c929",
            "value": " 612/612 [00:00&lt;00:00, 39.2kB/s]"
          }
        },
        "5ddb365990bc40f8882d3979652a8fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7f6bf9ad614af7b4209c39183a34f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b9e9ba049a445695e4522479cf6a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "105ec57f66a34e51ab5d7e2fd5e35295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c665f5317a34412ba05486046be03ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae4f29a92aa0488386b23eaa0c8a7c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8028c067fa4c4a9eda35661534c929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08f0fb2483264c8d8bf3ac8626eb7a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97663bbd7ab74a9f91207b3a44284800",
              "IPY_MODEL_4b994572d83344d68fbd76d654ed8b18",
              "IPY_MODEL_57a36a9a7e244715b886aba05bba9a3c"
            ],
            "layout": "IPY_MODEL_08d811caca004d3daf5ffc969ab5fb75"
          }
        },
        "97663bbd7ab74a9f91207b3a44284800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_694b933d116d48d3bbc17bf397e59838",
            "placeholder": "​",
            "style": "IPY_MODEL_11eca8abf96049a1bdce46f4c5f1d866",
            "value": "model.safetensors: 100%"
          }
        },
        "4b994572d83344d68fbd76d654ed8b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc47a509953483eac83117b0616e2c6",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b27d00cb53b4302a937a3f3c77589af",
            "value": 90868376
          }
        },
        "57a36a9a7e244715b886aba05bba9a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6781b3bc9b845ef857b2ce978967ee5",
            "placeholder": "​",
            "style": "IPY_MODEL_f59109b5913c446f9402808fdf446111",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 150MB/s]"
          }
        },
        "08d811caca004d3daf5ffc969ab5fb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694b933d116d48d3bbc17bf397e59838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11eca8abf96049a1bdce46f4c5f1d866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cc47a509953483eac83117b0616e2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b27d00cb53b4302a937a3f3c77589af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6781b3bc9b845ef857b2ce978967ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59109b5913c446f9402808fdf446111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11e6285ab0574cfaa5f0d96912b99596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07a6b5b5d07c4f9d9247cbda1e4ea264",
              "IPY_MODEL_4b564861330b45b5833e2a254e350cec",
              "IPY_MODEL_9c268e8c3aed4eb59b50c2889b98b58c"
            ],
            "layout": "IPY_MODEL_67322c4cd9f24bccaa6344d61fc0e086"
          }
        },
        "07a6b5b5d07c4f9d9247cbda1e4ea264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab23aeca65a34ff8b7af2c1ceeb31cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_47db4b1176c04c559e8efa237b944ffc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4b564861330b45b5833e2a254e350cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7eb87074fd45afb1a10b18ac6faa57",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b06d105964704b168bc1a01d38329c16",
            "value": 350
          }
        },
        "9c268e8c3aed4eb59b50c2889b98b58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0d30dc88d547e6944633e0336407e0",
            "placeholder": "​",
            "style": "IPY_MODEL_1c067a6f6f114d3f9a8d151f6e6545bc",
            "value": " 350/350 [00:00&lt;00:00, 22.3kB/s]"
          }
        },
        "67322c4cd9f24bccaa6344d61fc0e086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab23aeca65a34ff8b7af2c1ceeb31cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47db4b1176c04c559e8efa237b944ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d7eb87074fd45afb1a10b18ac6faa57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06d105964704b168bc1a01d38329c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a0d30dc88d547e6944633e0336407e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c067a6f6f114d3f9a8d151f6e6545bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1f1a37da5ca4f88be6bdfc0d2a7a1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b93e50024e4bcab56e634ace9b7c1c",
              "IPY_MODEL_1e4b3e524d664590b2f9dcddf2a6674a",
              "IPY_MODEL_0542752feaaa4e2aae91653b3daee94d"
            ],
            "layout": "IPY_MODEL_bf7d63e49c3b4057a536a111d765513b"
          }
        },
        "b3b93e50024e4bcab56e634ace9b7c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30feff0c713d472681a8bda4e11121ae",
            "placeholder": "​",
            "style": "IPY_MODEL_2120e51669e043c8862a67bd282b5018",
            "value": "vocab.txt: 100%"
          }
        },
        "1e4b3e524d664590b2f9dcddf2a6674a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_560c000c8a594ce38290e57fb79c91b5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e13af3e8ad5491b9590dbb70b8fb1f9",
            "value": 231508
          }
        },
        "0542752feaaa4e2aae91653b3daee94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0adc63c2b4c4b2d8a562716fd2cea97",
            "placeholder": "​",
            "style": "IPY_MODEL_c14a2270418644528a984223d68479cb",
            "value": " 232k/232k [00:00&lt;00:00, 4.63MB/s]"
          }
        },
        "bf7d63e49c3b4057a536a111d765513b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30feff0c713d472681a8bda4e11121ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2120e51669e043c8862a67bd282b5018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "560c000c8a594ce38290e57fb79c91b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e13af3e8ad5491b9590dbb70b8fb1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0adc63c2b4c4b2d8a562716fd2cea97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14a2270418644528a984223d68479cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4efd2bd4c84080a9fcf9788063e59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18c12a03286c49fdaaa0b3891490146a",
              "IPY_MODEL_24b952c2008f4b008d027e17b4845944",
              "IPY_MODEL_b19a277ed4094a8cabe7f0961c6e2adf"
            ],
            "layout": "IPY_MODEL_a75d3d8c07e54a87be8517d8f30eaa1d"
          }
        },
        "18c12a03286c49fdaaa0b3891490146a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8629fc13f2594eb99c9077569f0ebf41",
            "placeholder": "​",
            "style": "IPY_MODEL_af4162d2c2e84545bf67316412d136bc",
            "value": "tokenizer.json: 100%"
          }
        },
        "24b952c2008f4b008d027e17b4845944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cb504e09334dd4a692545beffe5bdc",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0be5a8fbddc4578836c92e0d11987b2",
            "value": 466247
          }
        },
        "b19a277ed4094a8cabe7f0961c6e2adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b851afdcdec478b9563b83c217c7433",
            "placeholder": "​",
            "style": "IPY_MODEL_07add51f44ce48eda6311060983f6ec4",
            "value": " 466k/466k [00:00&lt;00:00, 21.1MB/s]"
          }
        },
        "a75d3d8c07e54a87be8517d8f30eaa1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8629fc13f2594eb99c9077569f0ebf41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4162d2c2e84545bf67316412d136bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64cb504e09334dd4a692545beffe5bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0be5a8fbddc4578836c92e0d11987b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b851afdcdec478b9563b83c217c7433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07add51f44ce48eda6311060983f6ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae6553b04b5496c8921ed8c7cf222c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42a264c6bc81436fb645c5ec60a2b505",
              "IPY_MODEL_f43ac47d50d24604b7598320a976cfe6",
              "IPY_MODEL_7f3a177ec51f41e69fda990086da88fc"
            ],
            "layout": "IPY_MODEL_f6792efeccbd4c6d9f781dc9c989cb0b"
          }
        },
        "42a264c6bc81436fb645c5ec60a2b505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_443b3d998ef44501806adea909f3856f",
            "placeholder": "​",
            "style": "IPY_MODEL_db472ab4f8c94565b8280943d77793a0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f43ac47d50d24604b7598320a976cfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4121f4023f5744948c4a9df42d866567",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bcc4bb3024f4a15a29fb3c0781ad77b",
            "value": 112
          }
        },
        "7f3a177ec51f41e69fda990086da88fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235cfc0134004522974f1d5357f00b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_0446e0cceb434093b881b390fc25f514",
            "value": " 112/112 [00:00&lt;00:00, 6.88kB/s]"
          }
        },
        "f6792efeccbd4c6d9f781dc9c989cb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443b3d998ef44501806adea909f3856f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db472ab4f8c94565b8280943d77793a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4121f4023f5744948c4a9df42d866567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bcc4bb3024f4a15a29fb3c0781ad77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "235cfc0134004522974f1d5357f00b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0446e0cceb434093b881b390fc25f514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd4d2eb834344430a5017319b673febf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9f4598cb5bb452b9e6dd972cb5773e6",
              "IPY_MODEL_43a4cf85b77b4f25b85ee928a17afc33",
              "IPY_MODEL_f227f5a92f8744368532058e38f3d698"
            ],
            "layout": "IPY_MODEL_6d3c4b5d065b4625992109a2116227a6"
          }
        },
        "c9f4598cb5bb452b9e6dd972cb5773e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6327f6b28cbb4439abb7f24864b398a7",
            "placeholder": "​",
            "style": "IPY_MODEL_11078da9c5c640d29afbbd0ba1d15e68",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "43a4cf85b77b4f25b85ee928a17afc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d458e170993d4933a742cab642336458",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78efd476af644681874666cc89d815ff",
            "value": 190
          }
        },
        "f227f5a92f8744368532058e38f3d698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f87e4227155b47b1b4a1654434cbbe7c",
            "placeholder": "​",
            "style": "IPY_MODEL_21232b2962be4dc0a1bb77a1ecd2ef72",
            "value": " 190/190 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "6d3c4b5d065b4625992109a2116227a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6327f6b28cbb4439abb7f24864b398a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11078da9c5c640d29afbbd0ba1d15e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d458e170993d4933a742cab642336458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78efd476af644681874666cc89d815ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f87e4227155b47b1b4a1654434cbbe7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21232b2962be4dc0a1bb77a1ecd2ef72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwhI9H1A0_kj",
        "outputId": "6d74534f-d57f-42ef-f0cb-028f308fc683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Enter the YouTube URL: https://youtu.be/AdBzzpq3xV4?si=vUMkCWH-GiMPFxBe\n",
            "An error occurred: HTTP Error 403: Forbidden\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "\n",
        "from pytube import YouTube\n",
        "\n",
        "def download_youtube_audio(url):\n",
        "  \"\"\"Downloads the audio from a YouTube video.\n",
        "\n",
        "  Args:\n",
        "    url: The URL of the YouTube video.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "    audio_stream.download()\n",
        "    print(f\"Audio downloaded successfully: {audio_stream.default_filename}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Get the YouTube URL from the user\n",
        "video_url = input(\"Enter the YouTube URL: \")\n",
        "\n",
        "# Download the audio\n",
        "download_youtube_audio(video_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "def download_youtube_audio(url):\n",
        "  \"\"\"Downloads the audio from a YouTube video.\n",
        "\n",
        "  Args:\n",
        "    url: The URL of the YouTube video.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    yt = YouTube(url)\n",
        "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "    audio_stream.download()\n",
        "    print(f\"Audio downloaded successfully: {audio_stream.default_filename}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Get the YouTube URL from the user\n",
        "video_url = input(\"Enter the YouTube URL: \")\n",
        "\n",
        "# Download the audio\n",
        "download_youtube_audio(video_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv5nTvs02IE0",
        "outputId": "17b5bb24-68cc-442c-8905-e0abb30054fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube URL: https://www.youtube.com/watch?v=buKOl_cqgIM&list=RDTMY1g8pAktk&index=9\n",
            "An error occurred: HTTP Error 403: Forbidden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "link=\"https://www.youtube.com/watch?v=buKOl_cqgIM&list=RDTMY1g8pAktk&index=9\"\n",
        "\n",
        "youtube_1=YouTube(link)\n",
        "\n",
        "videos=youtube_1.streams.filter(only_audio=True)\n",
        "vid=list(enumerate(videos))\n",
        "for i in vid:\n",
        "    print(i)\n",
        "\n",
        "print()\n",
        "strm=int(input(\"enter :\"))\n",
        "videos[strm].download()\n",
        "print('succesfully')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5yGG7dze2Wqp",
        "outputId": "da31cfde-caa0-489b-9b13-9ba0e202d71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 403: Forbidden",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4c5bcd287e54>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0myoutube_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYouTube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvideos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myoutube_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_audio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mstreams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \"\"\"\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_availability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mStreamQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt_streams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mfmt_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fmt_streams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mstream_manifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_descrambler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# If the cached js doesn't work, try fetching a new js file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mstreaming_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'streamingData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbypass_age_gate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'streamingData'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mbypass_age_gate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mallow_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_oauth_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0minnertube_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnertube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mplayability_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minnertube_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playabilityStatus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/innertube.py\u001b[0m in \u001b[0;36mplayer\u001b[0;34m(self, video_id)\u001b[0m\n\u001b[1;32m    446\u001b[0m         }\n\u001b[1;32m    447\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/innertube.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, endpoint, query, data)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         response = request._execute_request(\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mendpoint_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/request.py\u001b[0m in \u001b[0;36m_execute_request\u001b[0;34m(url, method, headers, data, timeout)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid URL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# nosec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp\n",
        "!mkdir -p ./exports\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvEKp2Z923Id",
        "outputId": "f2fde288-ff56-4d1f-bcfb-bf406c510aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.1.12-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.1.12-py3-none-any.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m191.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def download_audio(url, output_file=None):\n",
        "    try:\n",
        "        # Construct the yt-dlp command\n",
        "        command = [\"yt-dlp\", \"-f\", \"bestaudio\", \"--extract-audio\", \"--audio-format\", \"mp3\"]\n",
        "        if output_file:\n",
        "            command.extend([\"-o\", f\"./exports/{output_file}.mp3\"])\n",
        "        else:\n",
        "            command.extend([\"-o\", \"./exports/%(title)s.%(ext)s\"])\n",
        "        command.append(url)\n",
        "\n",
        "        # Run the command\n",
        "        subprocess.run(command, check=True)\n",
        "        print(\"Audio downloaded successfully.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error downloading audio: {e}\")\n",
        "\n",
        "# Example usage in Colab\n",
        "url = \"https://www.youtube.com/watch?v=mONihsDGNxQ&list=RDTMY1g8pAktk&index=10\"\n",
        "output_file = \"/content/bb\"  # Replace with your desired filename or leave as None\n",
        "download_audio(url, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "d8XjP1Ag23L2",
        "outputId": "87f91618-b035-4228-c0a6-285cda46b4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e26e3a8616a3>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.youtube.com/watch?v=mONihsDGNxQ&list=RDTMY1g8pAktk&index=10\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/bb\"\u001b[0m  \u001b[0;31m# Replace with your desired filename or leave as None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-e26e3a8616a3>\u001b[0m in \u001b[0;36mdownload_audio\u001b[0;34m(url, output_file)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Run the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio downloaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def download_audio(url, output_file=None):\n",
        "    try:\n",
        "        # Construct the yt-dlp command\n",
        "        command = [\"yt-dlp\", \"-f\", \"bestaudio\", \"--extract-audio\", \"--audio-format\", \"mp3\"]\n",
        "        if output_file:\n",
        "            command.extend([\"-o\", output_file])  # Use the exact path provided\n",
        "        else:\n",
        "            command.extend([\"-o\", \"./exports/%(title)s.%(ext)s\"])  # Default path\n",
        "        command.append(url)\n",
        "\n",
        "        # Run the command\n",
        "        subprocess.run(command, check=True)\n",
        "        print(\"Audio downloaded successfully.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error downloading audio: {e}\")\n",
        "\n",
        "# Example usage in Colab\n",
        "url = \" youtube.com/watch?v=3XShkcOze3s&list=RDTMY1g8pAktk&index=11\"\n",
        "output_file = \"None\"  # Define the desired path\n",
        "download_audio(url, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "q78otf8K4v3t",
        "outputId": "b57c319e-a285-4c45-9afe-f55f2d7e133d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bda858b4de86>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" youtube.com/watch?v=3XShkcOze3s&list=RDTMY1g8pAktk&index=11\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"None\"\u001b[0m  \u001b[0;31m# Define the desired path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-bda858b4de86>\u001b[0m in \u001b[0;36mdownload_audio\u001b[0;34m(url, output_file)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Run the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio downloaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def download_audio(url, output_file=None):\n",
        "    try:\n",
        "        # Construct the yt-dlp command\n",
        "        command = [\"yt-dlp\", \"-f\", \"bestaudio\", \"--extract-audio\", \"--audio-format\", \"mp3\"]\n",
        "        if output_file:  # If a file name is specified\n",
        "            command.extend([\"-o\", output_file])\n",
        "        else:  # Default file name\n",
        "            command.extend([\"-o\", \"./exports/%(title)s.%(ext)s\"])\n",
        "        command.append(url)\n",
        "\n",
        "        # Run the command\n",
        "        print(\"Downloading audio...\")\n",
        "        subprocess.run(command, check=True, timeout=300)  # Add timeout (e.g., 5 minutes)\n",
        "        print(\"Audio downloaded successfully.\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"Error: Download process timed out.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error downloading audio: {e}\")\n",
        "\n",
        "# Example usage in Colab\n",
        "url = \"https://www.youtube.com/watch?v=3XShkcOze3s&list=RDTMY1g8pAktk&index=11\"\n",
        "output_file = None  # Use default behavior\n",
        "download_audio(url, output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "0Nc5qqns5ccf",
        "outputId": "9fbd8454-05de-46e5-e273-d9708b51dde4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading audio...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-69d32a64dd7b>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.youtube.com/watch?v=3XShkcOze3s&list=RDTMY1g8pAktk&index=11\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Use default behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdownload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-69d32a64dd7b>\u001b[0m in \u001b[0;36mdownload_audio\u001b[0;34m(url, output_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Run the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading audio...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add timeout (e.g., 5 minutes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio downloaded successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileobj2output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remaining_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[0;31m# All data exchanged.  Translate lists into strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#audio ,title description downlaod\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def download_audio_and_extract_info(url):\n",
        "    try:\n",
        "        # Construct the yt-dlp command for extracting video info\n",
        "        info_command = [\"yt-dlp\", \"--dump-json\", url]\n",
        "\n",
        "        # Run the command to get video info\n",
        "        print(\"Fetching video info...\")\n",
        "        result = subprocess.run(info_command, stdout=subprocess.PIPE, check=True, text=True)\n",
        "        video_info = json.loads(result.stdout)\n",
        "\n",
        "        # Extract title and description\n",
        "        title = video_info.get(\"title\", \"unknown_title\").replace(\" \", \"_\")  # Replace spaces with underscores for filenames\n",
        "        description = video_info.get(\"description\", \"No description available.\")\n",
        "\n",
        "        # Print title and description\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Description: {description}\")\n",
        "\n",
        "        # Construct the yt-dlp command for downloading audio\n",
        "        audio_command = [\n",
        "            \"yt-dlp\", \"-f\", \"bestaudio\", \"--extract-audio\", \"--audio-format\", \"mp3\",\n",
        "            \"-o\", f\"/content/{title}.mp3\", url\n",
        "        ]\n",
        "\n",
        "        # Run the command to download audio\n",
        "        print(\"Downloading audio...\")\n",
        "        subprocess.run(audio_command, check=True, timeout=300)\n",
        "        print(f\"Audio downloaded successfully as /content/{title}.mp3\")\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"Error: Download process timed out.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Failed to parse video information.\")\n",
        "\n",
        "# Example usage in Colab\n",
        "url = \"https://youtu.be/nsFJW7SZSD8?si=W4b5jYqLX-yGaCWJ\"  # Replace with your YouTube URL\n",
        "download_audio_and_extract_info(url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SPsxf2J67zr",
        "outputId": "f8223453-d424-4a72-a912-6578dfaf0139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching video info...\n",
            "Title: Jackie_Kannada_Video_Songs_Jukebox_|_Power_⭐_Puneeth_Rajkumar_|_Bhavana_|_V.Harikrishna_|_Suri\n",
            "Description: 📺 Watch Full Video Songs Jukebox from the Movie Jackie, Starring: Power ⭐ Puneeth Rajkumar, Bhavana and Others Exclusively on Anand Audio  Kannada Video Songs YouTube Channel...!!! \n",
            "-------------------------------------------------------------\n",
            "#jackie #puneethrajkumar #bhavanamenon #vharikrishna #yogarajbhat   \n",
            "-------------------------------------------------------------\n",
            "To Listen On Your Favourite Music Streaming Platform\n",
            "♪ Wynk Music: http://bit.ly/2YCiZUi\n",
            "♪ JioSaavn: http://bit.ly/2WpY1eB\n",
            "♪ Gaana Music: http://bit.ly/2YRBqJ9\n",
            "♪ Amazon Prime Music: https://amzn.to/2WCrL6x\n",
            "♪ Hungama: http://bit.ly/2WRsJ04\n",
            "♪ YouTube Music: https://bit.ly/38vIajc\n",
            "♪ Apple Music: https://apple.co/2KydbHd\n",
            "♪ Resso Music: https://m.resso.com/Zs8RTLV7F/\n",
            "♪ Spotify Music: https://spoti.fi/3cB1Nba\n",
            "♪ Jukebox: https://youtu.be/BvjV86EifZQ\n",
            "♪ Inst reels Shiva Anta Hogutidde: https://bit.ly/46q0y8M\n",
            "♪ Inst reels Eradu Jadeyannu: https://bit.ly/3CGK9Q1\n",
            "♪ Inst reels Ekka Raja Rani: https://bit.ly/46oVOjH\n",
            "♪ Inst reels Edavatt Aitu: Coming Soon\n",
            "♪ Inst reels Jackie Jackie: https://bit.ly/3iywNP1\n",
            "-------------------------------------------------------------\n",
            "♪ Banner: Sri Poornima Enterprises \n",
            "♪ Movie: Jackie \n",
            "♪ Producer: Raghavendra Rajkumar \n",
            "♪ Director: Suri \n",
            "♪ Music Director: V.Harikrishna \n",
            "♪ Starcast: Power ⭐ Puneeth Rajkumar, Bhavana Menon, Rangayana Ragu, \n",
            "♪ Lyrics: Yogaraj Bhat\n",
            "♪ Record Label: AANANDA AUDIO VIDEO\n",
            "-------------------------------------------------------------\n",
            "📺 Shiva Anta Hogutidde / Singer: Tippu\n",
            "📺 Eradu Jadeyannu / Singers: Sonu Nigam, Shreya Ghoshal\n",
            "📺 Ekka Raja Rani / Singer: Kailash Kher \n",
            "📺 Edavatt Aitu / Singers: Puneeth Rajkumar, Priya Hemesh\n",
            "📺 Jackie Jackie / Singer: Naveen Madhav\n",
            "-------------------------------------------------------------\n",
            "Operator Codes\n",
            "To Set this song \" Shiva Anta Hogutidde \" as Your Caller Tune!!!\n",
            "AirTel Users Dial 5432111657267 \n",
            "Vodafone & Idea Users Dial 53711809356 \n",
            "BSNL Users SMS BT 796448 to 56700 \n",
            "\n",
            "To Set this song \" Eradu Jadeyannu \" as Your Caller Tune!!!\n",
            "AirTel Users Dial 5432114142960 \n",
            "Vodafone & Idea Users Dial 53711809354 \n",
            "BSNL Users SMS BT 796445 to 56700 \n",
            "\n",
            "To Set this song \" Ekka Raja Rani \" as Your Caller Tune!!!\n",
            "AirTel Users Dial 5432111657264 \n",
            "Vodafone & Idea Users Dial 53711809353 \n",
            "BSNL Users SMS BT 796447 to 56700 \n",
            "\n",
            "To Set this song \"Edavatt Aitu\" as Your Caller Tune!!!\n",
            "AirTel Users Dial 5432114212072 \n",
            "Vodafone & Idea Users Dial 5372634487 \n",
            "BSNL Users SMS BT 2634487 to 56700 \n",
            "\n",
            "To Set this song \" Jackie Jackie \" as Your Caller Tune!!!\n",
            "AirTel Users Dial 5432111657266 \n",
            "Vodafone & Idea Users Dial 53711809355 \n",
            "BSNL Users SMS BT 796449 to 56700 \n",
            "-------------------------------------------------------------\n",
            "► Also Watch Top Love Songs: https://tinyurl.com/bd33csxw\n",
            "► Also Listen Compilation Audio Jukebox: https://tinyurl.com/5ez6s93z\n",
            "► Also Watch Latest Lyrical Videos: https://tinyurl.com/4z885692\n",
            "► Also Sing Along To Karaoke Songs: https://tinyurl.com/2x3b3e2t\n",
            "► Also Watch Kannada New Movies: https://tinyurl.com/4p5akcjz\n",
            "----------------------------------------------\n",
            "👉 *Twitter: https://twitter.com/aanandaaudio *\n",
            "👉 *Facebook: https://www.facebook.com/aanandaaudio * \n",
            "👉 *Instagram: https://www.instagram.com/aanandaaudio/ * \n",
            "----------------------------------------------\n",
            "VISIT OUR OTHER OFFICIAL CHANNELS:-\n",
            "►Anand Audio: http://goo.gl/JtObUW\n",
            "►Anand Audio Kannada: https://goo.gl/dLSjmK\n",
            "►Anand Audio Comedy: https://goo.gl/UFXUhq\n",
            "►Anand Audio Audio Songs: https://bit.ly/401TQ5d\n",
            "►Anand Audio Video Songs: https://bit.ly/40pbQXb\n",
            "►Anand Audio Lyrical Songs: https://bit.ly/40j0sMf\n",
            "►Anand Audio Full Movie Story: https://bit.ly/3n9wxYU\n",
            "►Anand Audio Karaoke: https://bit.ly/3hFMALq\n",
            "►Anand Audio DJ Remix: https://bit.ly/3TvtlCS\n",
            "►Anand Audio Entertainment: https://goo.gl/G2yx6X--\n",
            "►Anand Audio Shorts: https://bit.ly/40iIFF9\n",
            "►Anand Audio Telugu: https://bit.ly/2SVGx3b\n",
            "►Anand Audio Tamil: https://bit.ly/2NYSRyN\n",
            "►Anand Audio Malayalam: https://bit.ly/3yNQFSS\n",
            "►Anand Audio Hindi: https://bit.ly/3FxF91O\n",
            "►Anand Audio Devotional: https://goo.gl/73RHJR\n",
            "►Anand Audio Naadu Nudi: https://goo.gl/UCLZLj\n",
            "►Anand Audio North Karnataka: http://bit.do/eUktp\n",
            "►Anand Audio Tulu: https://goo.gl/v4cgYq\n",
            "----------------------------------------------\n",
            "Downloading audio...\n",
            "Audio downloaded successfully as /content/Jackie_Kannada_Video_Songs_Jukebox_|_Power_⭐_Puneeth_Rajkumar_|_Bhavana_|_V.Harikrishna_|_Suri.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub openai-whisper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huybEAJD96QM",
        "outputId": "b443b788-c552-45c7-bb50-6fd876d6311a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=a3548ab0c2894298d7d27866d23f8c4608b3003b73f6a541fce95256014a4eb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 pydub-0.25.1 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Transcribe the entire audio file\n",
        "def transcribe_audio_direct(file_path):\n",
        "    \"\"\"Transcribes the entire audio file without splitting.\"\"\"\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(\"small\")  # Use \"tiny\" or \"small\" for faster transcription on CPU\n",
        "\n",
        "    print(\"Transcribing audio...\")\n",
        "    result = model.transcribe(file_path)\n",
        "\n",
        "    transcription = result[\"text\"]\n",
        "    print(\"Transcription complete.\")\n",
        "    return transcription\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file = \"/content/Jackie_Kannada_Video_Songs_Jukebox_|_Power_⭐_Puneeth_Rajkumar_|_Bhavana_|_V.Harikrishna_|_Suri.mp3\"\n",
        "\n",
        "# Transcribe the audio file\n",
        "transcription_result = transcribe_audio_direct(audio_file)\n",
        "print(\"Transcription Result:\\n\", transcription_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "pQYHY1-p98R3",
        "outputId": "6c6757b0-4d4a-47bf-df91-575ed9b0493f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Whisper model...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:13<00:00, 34.9MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribing audio...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-50287db24a3d>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Transcribe the audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtranscription_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transcription Result:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-50287db24a3d>\u001b[0m in \u001b[0;36mtranscribe_audio_direct\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transcribing audio...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     ):\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     ):\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkv_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mxa\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         return F.linear(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PUZSOYTBhg-",
        "outputId": "e03bfed2-34a2-4517-ec86-149848e2095d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Path to your audio file\n",
        "audio_path = \"/content/Jackie_Kannada_Video_Songs_Jukebox_|_Power_⭐_Puneeth_Rajkumar_|_Bhavana_|_V.Harikrishna_|_Suri.mp3\"\n",
        "\n",
        "# Output folder for smaller segments\n",
        "segment_folder = \"segments\"\n",
        "os.makedirs(segment_folder, exist_ok=True)\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"tiny\")  # Use 'tiny' or 'base' model for faster transcription on CPU\n",
        "\n",
        "def split_audio(input_path, output_folder, segment_duration_ms=300000):\n",
        "    \"\"\"\n",
        "    Splits the audio file into smaller chunks of `segment_duration_ms`.\n",
        "    Saves them in the output folder.\n",
        "    \"\"\"\n",
        "    audio = AudioSegment.from_file(input_path)\n",
        "    total_duration = len(audio)\n",
        "\n",
        "    for i, start in enumerate(range(0, total_duration, segment_duration_ms)):\n",
        "        end = min(start + segment_duration_ms, total_duration)\n",
        "        segment = audio[start:end]\n",
        "        segment_path = os.path.join(output_folder, f\"segment_{i + 1}.mp3\")\n",
        "        segment.export(segment_path, format=\"mp3\")\n",
        "        print(f\"Exported: {segment_path}\")\n",
        "\n",
        "def transcribe_audio(folder_path):\n",
        "    \"\"\"\n",
        "    Transcribes all audio segments in the given folder.\n",
        "    \"\"\"\n",
        "    transcripts = []\n",
        "    for file in sorted(os.listdir(folder_path)):\n",
        "        if file.endswith(\".mp3\"):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            print(f\"Transcribing {file_path}...\")\n",
        "            result = model.transcribe(file_path, fp16=False)  # Disable fp16 for CPU\n",
        "            transcripts.append(result[\"text\"])\n",
        "    return \" \".join(transcripts)\n",
        "\n",
        "# Step 1: Split the audio file\n",
        "print(\"Splitting audio into smaller segments...\")\n",
        "split_audio(audio_path, segment_folder)\n",
        "\n",
        "# Step 2: Transcribe each segment\n",
        "print(\"Transcribing audio segments...\")\n",
        "final_transcription = transcribe_audio(segment_folder)\n",
        "\n",
        "# Save the transcription to a file\n",
        "transcription_path = \"transcription.txt\"\n",
        "with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_transcription)\n",
        "\n",
        "print(f\"Transcription completed and saved to {transcription_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "Bvri31kDBjId",
        "outputId": "1225fe19-991d-41f7-ab87-337b6d30b617"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 83.0MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting audio into smaller segments...\n",
            "Exported: segments/segment_1.mp3\n",
            "Exported: segments/segment_2.mp3\n",
            "Exported: segments/segment_3.mp3\n",
            "Exported: segments/segment_4.mp3\n",
            "Transcribing audio segments...\n",
            "Transcribing segments/segment_1.mp3...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dd390e388dbe>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Step 2: Transcribe each segment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transcribing audio segments...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mfinal_transcription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Save the transcription to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-dd390e388dbe>\u001b[0m in \u001b[0;36mtranscribe_audio\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Transcribing {file_path}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Disable fp16 for CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtranscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mn_audio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0maudio_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_audio_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# encoder forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_get_audio_features\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0maudio_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         if audio_features.dtype != (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         return F.linear(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Path to the audio file\n",
        "audio_file = \"/content/segments/segment_1.mp3\"\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"tiny\")  # Use 'tiny' or 'base' for faster transcription on CPU\n",
        "\n",
        "# Transcribe the audio\n",
        "print(f\"Transcribing {audio_file}...\")\n",
        "result = model.transcribe(audio_file, fp16=False)  # Disable fp16 for CPU\n",
        "transcription = result[\"text\"]\n",
        "\n",
        "# Output the transcription\n",
        "print(\"Transcription:\")\n",
        "print(transcription)\n",
        "\n",
        "# Save the transcription to a file\n",
        "output_path = \"segment_1_transcription.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcAnu3E9Ce51",
        "outputId": "657bb059-e117-4442-bd6b-5adf57821428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing /content/segments/segment_1.mp3...\n",
            "Transcription:\n",
            " ih 對 一 <|te|> 他 四 玲 乒 佢  MOOR Vij edited·Pa·Over Assembly Marangu.. Bora订布 Nor ocksåori 没有属 acknowled喂! View Andry eyes because he's a Jinn 왜 나를 smokesль hai sir pa! Kiny! Kiny!! Kiny!! Kiny!! Kiny! – Kiny!! Kiny!! S하기 l amateur Kiny!!اء �� yourself 兄弟 ・可  tiringID Ba BYI BURAN 你 野 好 野 好…�� 人 人 伪 Vice Retraction pevhe deana katneyyman me YOUR vote mekeilharwatt malen mekeble get leho da away la mappaisoft进着 כי着 כי着 כי着 jumpki kwamu cho аци kite进着进着屁 Sirmars, ‫ ищ trait Madam, ‫ ka you say you like ‫ just the bloodyời ‫ palms ashak � altro Lah ‫ hullo nimги inte父 ‫רךioVE, так mare ‫ You loveung me ne ! ‫ вiy boat idiot ... Grant near Krishna gota pumpkin man we are your tidyingran, we are buried we are being predominantly õõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõõ\n",
            "Transcription saved to segment_1_transcription.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-speech\n",
        "!pip install pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "cpYIZMkDFPG6",
        "outputId": "1f6597ad-d4e4-4be4-f73c-61cc8c9ec8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-speech\n",
            "  Downloading google_cloud_speech-2.30.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (4.25.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.12.14)\n",
            "Downloading google_cloud_speech-2.30.0-py2.py3-none-any.whl (324 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/324.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.2/324.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-speech\n",
            "Successfully installed google-cloud-speech-2.30.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "b390c1ff066f44c3a61f10bef8cda6b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywcwV0EMFhhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import speech\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file = \"/content/segments/segment_1.mp3\"\n",
        "\n",
        "# Convert MP3 to WAV (Google Speech-to-Text works best with WAV format)\n",
        "def convert_to_wav(input_path, output_path):\n",
        "    audio = AudioSegment.from_mp3(input_path)\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "    return output_path\n",
        "\n",
        "# Transcribe the audio using Google Speech-to-Text\n",
        "def transcribe_audio(wav_file):\n",
        "    client = speech.SpeechClient()\n",
        "\n",
        "    # Read the audio file\n",
        "    with open(wav_file, \"rb\") as audio_file:\n",
        "        content = audio_file.read()\n",
        "\n",
        "    # Configure the recognition\n",
        "    audio = speech.RecognitionAudio(content=content)\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        sample_rate_hertz=16000,  # Adjust based on your audio's sample rate\n",
        "        language_code=\"en-US\"    # Change to your desired language code\n",
        "    )\n",
        "\n",
        "    # Perform transcription\n",
        "    response = client.recognize(config=config, audio=audio)\n",
        "\n",
        "    # Collect the transcription\n",
        "    transcription = \" \".join([result.alternatives[0].transcript for result in response.results])\n",
        "    return transcription\n",
        "\n",
        "# Convert MP3 to WAV\n",
        "wav_path = \"/content/segments/segment_1.wav\"\n",
        "convert_to_wav(audio_file, wav_path)\n",
        "\n",
        "# Transcribe the WAV file\n",
        "print(f\"Transcribing {wav_path}...\")\n",
        "transcription = transcribe_audio(wav_path)\n",
        "\n",
        "# Output the transcription\n",
        "print(\"Transcription:\")\n",
        "print(transcription)\n",
        "\n",
        "# Save the transcription to a file\n",
        "output_path = \"segment_1_transcription.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "veLtvk5gFScL",
        "outputId": "b12d0fa3-3c29-490c-d675-bf2901d74bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing /content/segments/segment_1.wav...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1eab30>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1eab30>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1ebb20>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1ebb20>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8940>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8940>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8430>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8430>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1bf9a0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1bf9a0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1be530>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1be530>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8430>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8430>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1be020>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1be020>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1bfca0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1bfca0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20db70>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20db70>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c430>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c430>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1be020>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1be020>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20dba0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20dba0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c2b0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c2b0>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20e290>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20e290>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1bec50>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1bec50>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8a00>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1e8a00>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1eaa10>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d1eaa10>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20f520>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20f520>)\n",
            "ERROR:grpc._plugin_wrapping:AuthMetadataPluginCallback \"<google.auth.transport.grpc.AuthMetadataPlugin object at 0x7f333d159870>\" raised exception!\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 128, in refresh\n",
            "    self._retrieve_info(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 101, in _retrieve_info\n",
            "    info = _metadata.get_service_account_info(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 323, in get_service_account_info\n",
            "    return get(request, path, params={\"recursive\": \"true\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/_metadata.py\", line 248, in get\n",
            "    raise exceptions.TransportError(\n",
            "google.auth.exceptions.TransportError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c3d0>)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_plugin_wrapping.py\", line 105, in __call__\n",
            "    self._metadata_plugin(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 95, in __call__\n",
            "    callback(self._get_authorization_headers(context), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/transport/grpc.py\", line 81, in _get_authorization_headers\n",
            "    self._credentials.before_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 228, in before_request\n",
            "    self._blocking_refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/credentials.py\", line 191, in _blocking_refresh\n",
            "    self.refresh(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/auth/compute_engine/credentials.py\", line 134, in refresh\n",
            "    raise new_exc from caught_exc\n",
            "google.auth.exceptions.RefreshError: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c3d0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    276\u001b[0m     ) -> Any:\n\u001b[0;32m--> 277\u001b[0;31m         response, ignored_call = self._with_call(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36m_with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;34m\"\"\"See grpc.Future.result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_interceptor.py\u001b[0m in \u001b[0;36mcontinuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 response, call = self._thunk(new_method).with_call(\n\u001b[0m\u001b[1;32m    316\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36mwith_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1197\u001b[0m         )\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c3d0>)\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-01-15T13:10:09.528862198+00:00\", grpc_status:14, grpc_message:\"Getting metadata from plugin failed with error: (\\\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\\\nb\\'\\'\\\", <google.auth.transport.requests._Response object at 0x7f333d20c3d0>)\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServiceUnavailable\u001b[0m: 503 Getting metadata from plugin failed with error: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Engine metadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7f333d20c3d0>)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7043a2640969>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Transcribe the WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Transcribing {wav_path}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Output the transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7043a2640969>\u001b[0m in \u001b[0;36mtranscribe_audio\u001b[0;34m(wav_file)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Perform transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Collect the transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/speech_v1/services/speech/client.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, request, config, audio, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    817\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             )\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# if exception not raised, sleep before next attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sleep generator stopped yielding sleep values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk\n",
        "!pip install pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxrEH_WBFQlK",
        "outputId": "780dd927-c93d-4fae-e431-d895b0f06be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from vosk) (14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2024.12.14)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=873c17352027d4691348c243e0b0284f1450568098c18a61821d6ca702a1c1fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# Define the URL for the Vosk model\n",
        "vosk_model_url = \"https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\"\n",
        "vosk_model_path = \"/content/vosk-model-small-en-us\"\n",
        "\n",
        "# Download the model if it doesn't exist\n",
        "if not os.path.exists(vosk_model_path):\n",
        "    print(\"Downloading Vosk model...\")\n",
        "    model_zip_path = \"/content/vosk-model-small-en-us.zip\"\n",
        "    response = requests.get(vosk_model_url, stream=True)\n",
        "\n",
        "    # Save the zip file\n",
        "    with open(model_zip_path, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "    # Extract the zip file\n",
        "    print(\"Extracting the Vosk model...\")\n",
        "    with zipfile.ZipFile(model_zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"/content/\")\n",
        "    print(f\"Model extracted to {vosk_model_path}.\")\n",
        "\n",
        "    # Clean up the zip file\n",
        "    os.remove(model_zip_path)\n",
        "else:\n",
        "    print(f\"Vosk model already exists at {vosk_model_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJQbue5zHfKs",
        "outputId": "265c41cf-49ee-41d9-94af-b6634f8be786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Vosk model...\n",
            "Download complete.\n",
            "Extracting the Vosk model...\n",
            "Model extracted to /content/vosk-model-small-en-us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Path to your Vosk model directory\n",
        "vosk_model_path = \"/content/vosk-model-small-en-us-0.15\"\n",
        "\n",
        "# Path to the audio file\n",
        "audio_file = \"/content/segments/segment_1.mp3\"\n",
        "\n",
        "# Convert MP3 to WAV (Vosk requires WAV format)\n",
        "def convert_to_wav(input_path, output_path):\n",
        "    audio = AudioSegment.from_mp3(input_path)\n",
        "    audio = audio.set_channels(1)  # Vosk requires mono audio\n",
        "    audio = audio.set_frame_rate(16000)  # Recommended sampling rate for Vosk\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "    return output_path\n",
        "\n",
        "# Transcribe the audio using Vosk\n",
        "def transcribe_audio(wav_file, model_path):\n",
        "    # Load the Vosk model\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found at {model_path}. Please download it first.\")\n",
        "\n",
        "    model = Model(model_path)\n",
        "    recognizer = KaldiRecognizer(model, 16000)\n",
        "\n",
        "    # Read the audio file\n",
        "    with wave.open(wav_file, \"rb\") as wf:\n",
        "        if wf.getnchannels() != 1 or wf.getframerate() != 16000:\n",
        "            raise ValueError(\"Audio file must be mono and 16kHz.\")\n",
        "        transcription = []\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if recognizer.AcceptWaveform(data):\n",
        "                result = json.loads(recognizer.Result())\n",
        "                transcription.append(result.get(\"text\", \"\"))\n",
        "\n",
        "        # Add final partial transcription\n",
        "        final_result = json.loads(recognizer.FinalResult())\n",
        "        transcription.append(final_result.get(\"text\", \"\"))\n",
        "\n",
        "    return \" \".join(transcription)\n",
        "\n",
        "# Convert MP3 to WAV\n",
        "wav_path = \"/content/segments/segment_1.wav\"\n",
        "convert_to_wav(audio_file, wav_path)\n",
        "\n",
        "# Transcribe the WAV file\n",
        "print(f\"Transcribing {wav_path} using Vosk...\")\n",
        "transcription = transcribe_audio(wav_path, vosk_model_path)\n",
        "\n",
        "# Output the transcription\n",
        "print(\"Transcription:\")\n",
        "print(transcription)\n",
        "\n",
        "# Save the transcription to a file\n",
        "output_path = \"segment_1_transcription.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8IkFRv3G_w9",
        "outputId": "6d882d43-68c0-4738-a423-aafa59241cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing /content/segments/segment_1.wav using Vosk...\n",
            "Transcription:\n",
            " monitor of corner cutting your time you know but that's a lot to do too he did oh hoo i am no a lot okay the paper a decade hm       every eleven whatever  but his job a joke you're not going to take better than a decade      by your does not allow could go unless like that can say you know but done that that them make don't get goes up paternal but everybody already arrived the russian but they found that the and have get a panel that night he ran up the package that that hm    not only a good novel on it of vehicles on jean he found out good luck he then you or on our data the checked by to equal but a lot of our that about that of op rock bottom that a bomb that about that of our  the got are just running on your you my new denial biology the he not bio panda he and get he paid only any gotta do or the i don't know it bio    \n",
            "Transcription saved to segment_1_transcription.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final transcription\n",
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Path to your Vosk model directory\n",
        "vosk_model_path = \"/content/vosk-model-small-en-us-0.15\"\n",
        "\n",
        "# Path to the audio file\n",
        "audio_file = \"/content/Jackie_Kannada_Video_Songs_Jukebox_|_Power_⭐_Puneeth_Rajkumar_|_Bhavana_|_V.Harikrishna_|_Suri.mp3\"\n",
        "\n",
        "# Convert MP3 to WAV (Vosk requires WAV format)\n",
        "def convert_to_wav(input_path, output_path):\n",
        "    audio = AudioSegment.from_mp3(input_path)\n",
        "    audio = audio.set_channels(1)  # Vosk requires mono audio\n",
        "    audio = audio.set_frame_rate(16000)  # Recommended sampling rate for Vosk\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "    return output_path\n",
        "\n",
        "# Transcribe the audio using Vosk\n",
        "def transcribe_audio(wav_file, model_path):\n",
        "    # Load the Vosk model\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found at {model_path}. Please download it first.\")\n",
        "\n",
        "    model = Model(model_path)\n",
        "    recognizer = KaldiRecognizer(model, 16000)\n",
        "\n",
        "    # Read the audio file\n",
        "    with wave.open(wav_file, \"rb\") as wf:\n",
        "        if wf.getnchannels() != 1 or wf.getframerate() != 16000:\n",
        "            raise ValueError(\"Audio file must be mono and 16kHz.\")\n",
        "        transcription = []\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if recognizer.AcceptWaveform(data):\n",
        "                result = json.loads(recognizer.Result())\n",
        "                transcription.append(result.get(\"text\", \"\"))\n",
        "\n",
        "        # Add final partial transcription\n",
        "        final_result = json.loads(recognizer.FinalResult())\n",
        "        transcription.append(final_result.get(\"text\", \"\"))\n",
        "\n",
        "    return \" \".join(transcription)\n",
        "\n",
        "# Convert MP3 to WAV\n",
        "wav_path = \"/content/segments/dd.wav\"\n",
        "convert_to_wav(audio_file, wav_path)\n",
        "\n",
        "# Transcribe the WAV file\n",
        "print(f\"Transcribing {wav_path} using Vosk...\")\n",
        "transcription = transcribe_audio(wav_path, vosk_model_path)\n",
        "\n",
        "# Output the transcription\n",
        "print(\"Transcription:\")\n",
        "print(transcription)\n",
        "\n",
        "# Save the transcription to a file\n",
        "output_path = \"segment_1_transcription.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUATZnknIAzv",
        "outputId": "1a2713f8-aaff-4634-82f3-45e48a011fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing /content/segments/dd.wav using Vosk...\n",
            "Transcription:\n",
            " monitor the slot corner cutting your time they do but does a lot do that too he did obama i am no a lot okay today's paper a decade hm       everybody eleven oh one come on but lost his job and a joke candidate better than a decade  me    they don't mind it does not like could go unless i can say you know but done and that them make don't look at goes up paternal a but everybody rewrite the russian bird may sound like the and have get more a panel night he ran up so package that the that be back done    not only about a good novel on a little bit but go big or on team found out no longer they be allowed to do about it he then you banned or no not a decade that you need to be detected by to equal but a bomb but of our little bottom of op little bottom that a bomb that about that of our  he got are just running on your immunity my new denial biology the he remarked you're not bio panda he and get he paid only any gotta do or the i don't know it even bio       like are the two hundred tech guru like an overdue all part of to on the deck all i didn't know who do below the leopard landmark and need to pull a new one that on the band or no end in louisiana all i am muscle oh god now too bad that's legit he is too bad sign to magnify the fact that he dado nanny ninety already hey deputy one bio  you know       boolean the right to be the labor i do the other than that i do ya boy labour i do hello l like guidebook or now a boutique to move pass him on monday know show can be the i knew my nobody corn and grew up on the nicola to as liberty the liberty arrow name my name marty really yeah in and they are in name on no no number  even not on he obey their own any got to already the     we want our whole good did the old a gnarly sit beside i to life in our league or don't poop at it do biking ali the gun the society and early going to come to the guy to the complete guide to hot enough gotcha actually and to bend the knee plague the     yeah so maybe put a younger double been going to assume their people younger well what the much i parallel a lot them there are a lot the boy move in the double down on movie that were gone on to vulnerable every month grass on google palm hey rhonda hold it did the old a gnarly sick or assad i or life a gnarly hidalgo petrol to biking ali the side oh come   the manila but oh okay that two kg did i do okay the what my i can't wait to be the ideal russian turtle bay because will be a nation title back a bit loopy some that a little  three on the whole good did the already gnarly sync up but this allow you to lie for gnarly banco petrol it to biking ali the gun deciding early got to put to than guy to hire the complete fool up and guy too hot check than guy to been playing    jt new you need to good movie new nice so funny and your internet and the the burden the bernini about it we need to run a young dude cool go the objective and a dish don't know one another in a nanny or so the the needy do midi we need you to leave me oh god so they made so edit       league the when you do good burger bar the i sun jail he will see movies the know this girl no nina okay the the meeting we need to lean about gonna say the the      to  a hobby mean that can the loonies of or much ever again the jt hindu you need to get a do nice when i mean the journal to earn their money he know the burden on the mean a bird and yeah about typo get right though yeah about that i get up get out a lot yeah i i like that but us again the bnp get about diaper baby i put go and other guy the bad        ah oh god i go ahead the so a nice career subway asked about this way okay i gotta okay        see got nobody to and body bulletin of other side they say way learn a lot more people can see them again burnett chance this but a statement  robert yeah  yeah about die too  \n",
            "Transcription saved to segment_1_transcription.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peL78SVDJ-_9",
        "outputId": "e8b6a451-7415-4c66-b62e-ec2ea32270bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2whEV_7sJ1by",
        "outputId": "9eaa7e3d-d8ad-40d7-d4ac-564377026234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement deepspeech (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for deepspeech\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "from deepspeech import Model\n",
        "\n",
        "# Paths for the DeepSpeech model and scorer\n",
        "deepspeech_model_url = \"https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\"\n",
        "deepspeech_scorer_url = \"https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\"\n",
        "\n",
        "model_path = \"/content/deepspeech-0.9.3-models.pbmm\"\n",
        "scorer_path = \"/content/deepspeech-0.9.3-models.scorer\"\n",
        "\n",
        "# Function to download the model and scorer\n",
        "def download_deepspeech_assets():\n",
        "    if not os.path.exists(model_path):\n",
        "        print(\"Downloading DeepSpeech model...\")\n",
        "        subprocess.run([\"wget\", deepspeech_model_url, \"-O\", model_path], check=True)\n",
        "    else:\n",
        "        print(\"DeepSpeech model already downloaded.\")\n",
        "\n",
        "    if not os.path.exists(scorer_path):\n",
        "        print(\"Downloading DeepSpeech scorer...\")\n",
        "        subprocess.run([\"wget\", deepspeech_scorer_url, \"-O\", scorer_path], check=True)\n",
        "    else:\n",
        "        print(\"DeepSpeech scorer already downloaded.\")\n",
        "\n",
        "# Download DeepSpeech model and scorer\n",
        "download_deepspeech_assets()\n",
        "\n",
        "# Function to convert audio to WAV (16kHz, mono)\n",
        "def convert_to_wav(input_path, output_path):\n",
        "    audio = AudioSegment.from_file(input_path)\n",
        "    audio = audio.set_channels(1)  # Mono\n",
        "    audio = audio.set_frame_rate(16000)  # 16kHz sampling rate\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "    return output_path\n",
        "\n",
        "# Transcribe audio using DeepSpeech\n",
        "def transcribe_audio(audio_path, model_path, scorer_path):\n",
        "    print(\"Loading DeepSpeech model...\")\n",
        "    model = Model(model_path)\n",
        "    model.enableExternalScorer(scorer_path)\n",
        "\n",
        "    # Process audio file\n",
        "    with open(audio_path, \"rb\") as audio_file:\n",
        "        audio_data = audio_file.read()\n",
        "\n",
        "    print(\"Transcribing audio...\")\n",
        "    transcription = model.stt(audio_data)\n",
        "    return transcription\n",
        "\n",
        "# Input and output paths\n",
        "input_audio = \"/content/Jackie_Kannada_Video_Songs_Jukebox_|_Power_⭐_Puneeth_Rajkumar_|_Bhavana_|_V.Harikrishna_|_Suri.mp3\"\n",
        "wav_audio = \"/content/segments/qq.wav\"\n",
        "\n",
        "# Convert MP3 to WAV\n",
        "convert_to_wav(input_audio, wav_audio)\n",
        "\n",
        "# Transcribe the WAV audio\n",
        "print(\"Starting transcription with DeepSpeech...\")\n",
        "transcription = transcribe_audio(wav_audio, model_path, scorer_path)\n",
        "\n",
        "# Output transcription\n",
        "print(\"Transcription:\")\n",
        "print(transcription)\n",
        "\n",
        "# Save transcription to a file\n",
        "output_path = \"/content/segment_1_transcriptionq.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "s9pEiEemJrCH",
        "outputId": "206e41de-721d-45df-886b-e82d88395815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deepspeech'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-916bc89ad16d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepspeech\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Paths for the DeepSpeech model and scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepspeech'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import json\n",
        "\n",
        "def download_audio_and_extract_info(url):\n",
        "    try:\n",
        "        # Construct the yt-dlp command for extracting video info\n",
        "        info_command = [\"yt-dlp\", \"--dump-json\", url]\n",
        "\n",
        "        # Run the command to get video info\n",
        "        print(\"Fetching video info...\")\n",
        "        result = subprocess.run(info_command, stdout=subprocess.PIPE, check=True, text=True)\n",
        "        video_info = json.loads(result.stdout)\n",
        "\n",
        "        # Extract title and description\n",
        "        title = video_info.get(\"title\", \"unknown_title\").replace(\" \", \"_\")  # Replace spaces with underscores for filenames\n",
        "        description = video_info.get(\"description\", \"No description available.\")\n",
        "\n",
        "        # Print title and description\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Description: {description}\")\n",
        "\n",
        "        # Construct the yt-dlp command for downloading audio in .wav format\n",
        "        audio_command = [\n",
        "            \"yt-dlp\", \"-f\", \"bestaudio\", \"--extract-audio\", \"--audio-format\", \"wav\",\n",
        "            \"-o\", f\"/content/{title}.wav\", url\n",
        "        ]\n",
        "\n",
        "        # Run the command to download audio\n",
        "        print(\"Downloading audio...\")\n",
        "        subprocess.run(audio_command, check=True, timeout=300)\n",
        "        print(f\"Audio downloaded successfully as /content/{title}.wav\")\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"Error: Download process timed out.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Failed to parse video information.\")\n",
        "\n",
        "# Example usage\n",
        "url = \"https://www.youtube.com/watch?v=6GQRb4fGvtk\"  # Replace with your YouTube URL\n",
        "download_audio_and_extract_info(url)\n"
      ],
      "metadata": {
        "id": "uso45jfHKzbi",
        "outputId": "27b639db-5033-4535-e65a-88935972a4d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching video info...\n",
            "Title: The_Complete_DevOps_Roadmap\n",
            "Description: Go from zero to a DevOps Engineer in 10-14 months. This step-by-step roadmap covers the essential skills you need to become a DevOps Engineer in 2024. \n",
            "\n",
            "❤️ Join this channel to get access to perks:\n",
            "https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA/join\n",
            "\n",
            "Download the FREE roadmap PDF here: https://mosh.link/devops-roadmap\n",
            "\n",
            "✋ Stay connected\n",
            "\n",
            "- Complete courses: https://codewithmosh.com\n",
            "- Twitter: https://twitter.com/moshhamedani\n",
            "- Facebook: https://www.facebook.com/programmingwithmosh/\n",
            "- Instagram: https://www.instagram.com/codewithmosh.official/\n",
            "- LinkedIn: https://www.linkedin.com/school/codewithmosh/\n",
            "\n",
            "📚 Tutorials \n",
            "\n",
            "https://youtu.be/_uQrJ0TkZlc?si=ZhlCrQs1SkaPNVa8\n",
            "https://youtu.be/8JJ101D3knE?si=OGTuS35LQqSunuhh\n",
            "https://youtu.be/pTFZFxd4hOI?si=DkijlBq9w076bm2l\n",
            "\n",
            "📖 Chapters\n",
            "\n",
            "00:00 - Introduction\n",
            "00:25 - Linux Fundamentals\n",
            "00:59 - Networking Concepts\n",
            "01:38 - Git\n",
            "02:03 - Programming Languages\n",
            "03:03 - Cloud Providers\n",
            "03:36 - Containerization\n",
            "04:04 - Continuous Integration/Continuous Deployment (CI/CD)\n",
            "04:51 - Container Orchestration\n",
            "05:28 - Networking & Infrastructure Services \n",
            "06:00 - Configuration Management \n",
            "06:26 - Infrastructure as Code (IaC)\n",
            "07:04 - Monitoring & Logging\n",
            "\n",
            "#devops\n",
            "Downloading audio...\n",
            "Audio downloaded successfully as /content/The_Complete_DevOps_Roadmap.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "17LRod8yKzdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5mFCsjDKzfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yorKyYBsKzhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJamPZbkKzjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnQF1QCTKzlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xev2ZUmaKznK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzDze8ygKzrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iAHjnOE2Kzs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#audio ,title description downlaod\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def download_audio_and_extract_info(url):\n",
        "    try:\n",
        "        # Construct the yt-dlp command for extracting video info\n",
        "        info_command = [\"yt-dlp\", \"--dump-json\", url]\n",
        "\n",
        "        # Run the command to get video info\n",
        "        print(\"Fetching video info...\")\n",
        "        result = subprocess.run(info_command, stdout=subprocess.PIPE, check=True, text=True)\n",
        "        video_info = json.loads(result.stdout)\n",
        "\n",
        "        # Extract title and description\n",
        "        title = video_info.get(\"title\", \"unknown_title\").replace(\" \", \"_\")  # Replace spaces with underscores for filenames\n",
        "        description = video_info.get(\"description\", \"No description available.\")\n",
        "\n",
        "        # Print title and description\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Description: {description}\")\n",
        "\n",
        "        # Construct the yt-dlp command for downloading audio\n",
        "        audio_command = [\n",
        "            \"yt-dlp\", \"-f\", \"bestaudio\", \"--extract-audio\", \"--audio-format\", \"mp3\",\n",
        "            \"-o\", f\"/content/{title}.mp3\", url\n",
        "        ]\n",
        "\n",
        "        # Run the command to download audio\n",
        "        print(\"Downloading audio...\")\n",
        "        subprocess.run(audio_command, check=True, timeout=300)\n",
        "        print(f\"Audio downloaded successfully as /content/{title}.mp3\")\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"Error: Download process timed out.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Failed to parse video information.\")\n",
        "\n",
        "# Example usage in Colab\n",
        "url = \"https://www.youtube.com/watch?v=6GQRb4fGvtk\"  # Replace with your YouTube URL\n",
        "download_audio_and_extract_info(url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F45DoWHSKzu9",
        "outputId": "41be6681-44ee-4b92-e9ed-179fc839b261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching video info...\n",
            "Title: The_Complete_DevOps_Roadmap\n",
            "Description: Go from zero to a DevOps Engineer in 10-14 months. This step-by-step roadmap covers the essential skills you need to become a DevOps Engineer in 2024. \n",
            "\n",
            "❤️ Join this channel to get access to perks:\n",
            "https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA/join\n",
            "\n",
            "Download the FREE roadmap PDF here: https://mosh.link/devops-roadmap\n",
            "\n",
            "✋ Stay connected\n",
            "\n",
            "- Complete courses: https://codewithmosh.com\n",
            "- Twitter: https://twitter.com/moshhamedani\n",
            "- Facebook: https://www.facebook.com/programmingwithmosh/\n",
            "- Instagram: https://www.instagram.com/codewithmosh.official/\n",
            "- LinkedIn: https://www.linkedin.com/school/codewithmosh/\n",
            "\n",
            "📚 Tutorials \n",
            "\n",
            "https://youtu.be/_uQrJ0TkZlc?si=ZhlCrQs1SkaPNVa8\n",
            "https://youtu.be/8JJ101D3knE?si=OGTuS35LQqSunuhh\n",
            "https://youtu.be/pTFZFxd4hOI?si=DkijlBq9w076bm2l\n",
            "\n",
            "📖 Chapters\n",
            "\n",
            "00:00 - Introduction\n",
            "00:25 - Linux Fundamentals\n",
            "00:59 - Networking Concepts\n",
            "01:38 - Git\n",
            "02:03 - Programming Languages\n",
            "03:03 - Cloud Providers\n",
            "03:36 - Containerization\n",
            "04:04 - Continuous Integration/Continuous Deployment (CI/CD)\n",
            "04:51 - Container Orchestration\n",
            "05:28 - Networking & Infrastructure Services \n",
            "06:00 - Configuration Management \n",
            "06:26 - Infrastructure as Code (IaC)\n",
            "07:04 - Monitoring & Logging\n",
            "\n",
            "#devops\n",
            "Downloading audio...\n",
            "Audio downloaded successfully as /content/The_Complete_DevOps_Roadmap.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final transcription\n",
        "from vosk import Model, KaldiRecognizer\n",
        "import wave\n",
        "import json\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "# Path to your Vosk model directory\n",
        "vosk_model_path = \"/content/vosk-model-small-en-us-0.15\"\n",
        "\n",
        "# Path to the audio file\n",
        "audio_file = \"/content/The_Complete_DevOps_Roadmap.mp3\"\n",
        "\n",
        "# Convert MP3 to WAV (Vosk requires WAV format)\n",
        "def convert_to_wav(input_path, output_path):\n",
        "    audio = AudioSegment.from_mp3(input_path)\n",
        "    audio = audio.set_channels(1)  # Vosk requires mono audio\n",
        "    audio = audio.set_frame_rate(16000)  # Recommended sampling rate for Vosk\n",
        "    audio.export(output_path, format=\"wav\")\n",
        "    return output_path\n",
        "\n",
        "# Transcribe the audio using Vosk\n",
        "def transcribe_audio(wav_file, model_path):\n",
        "    # Load the Vosk model\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found at {model_path}. Please download it first.\")\n",
        "\n",
        "    model = Model(model_path)\n",
        "    recognizer = KaldiRecognizer(model, 16000)\n",
        "\n",
        "    # Read the audio file\n",
        "    with wave.open(wav_file, \"rb\") as wf:\n",
        "        if wf.getnchannels() != 1 or wf.getframerate() != 16000:\n",
        "            raise ValueError(\"Audio file must be mono and 16kHz.\")\n",
        "        transcription = []\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if recognizer.AcceptWaveform(data):\n",
        "                result = json.loads(recognizer.Result())\n",
        "                transcription.append(result.get(\"text\", \"\"))\n",
        "\n",
        "        # Add final partial transcription\n",
        "        final_result = json.loads(recognizer.FinalResult())\n",
        "        transcription.append(final_result.get(\"text\", \"\"))\n",
        "\n",
        "    return \" \".join(transcription)\n",
        "\n",
        "# Convert MP3 to WAV\n",
        "wav_path = \"/content/segments/dd.wav\"\n",
        "convert_to_wav(audio_file, wav_path)\n",
        "\n",
        "# Transcribe the WAV file\n",
        "print(f\"Transcribing {wav_path} using Vosk...\")\n",
        "transcription = transcribe_audio(wav_path, vosk_model_path)\n",
        "\n",
        "# Output the transcription\n",
        "print(\"Transcription:\")\n",
        "print(transcription)\n",
        "\n",
        "# Save the transcription to a file\n",
        "output_path = \"segment_1_transcription.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBh76h2SLJZ7",
        "outputId": "6fe2a875-e655-49fc-9f8a-43be09704df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing /content/segments/dd.wav using Vosk...\n",
            "Transcription:\n",
            "if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \n",
            "Transcription saved to segment_1_transcription.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "import requests\n",
        "\n",
        "# Replace with your Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# File path to the transcription text file\n",
        "file_path = 'segment_1_transcription.txt'\n",
        "\n",
        "# Load the content of the transcription\n",
        "with open(file_path, 'r') as file:\n",
        "    transcription_text = file.read()\n",
        "\n",
        "# Set up the headers for the request with the Gemini API key\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Set up the request payload\n",
        "payload = {\n",
        "    \"text\": transcription_text,\n",
        "    \"operation\": \"summarize\"  # Assuming Gemini allows a 'summarize' operation\n",
        "}\n",
        "\n",
        "# Make the request to Gemini API\n",
        "url = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent'  # Make sure to replace this URL with the actual one for Gemini API\n",
        "\n",
        "response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "# Check the response status and print the summarized text\n",
        "if response.status_code == 200:\n",
        "    summary = response.json().get('summary', 'No summary available')\n",
        "    print(f\"Summary: {summary}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4jmWKO3Lltq",
        "outputId": "47fcb40a-b1b6-4681-cb79-5b36ef09b204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Error: 401, {\n",
            "  \"error\": {\n",
            "    \"code\": 401,\n",
            "    \"message\": \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n",
            "    \"status\": \"UNAUTHENTICATED\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'  # Use your full API key\n",
        "\n",
        "# File path to the transcription text file\n",
        "file_path = 'segment_1_transcription.txt'\n",
        "\n",
        "# Load the content of the transcription\n",
        "with open(file_path, 'r') as file:\n",
        "    transcription_text = file.read()\n",
        "\n",
        "# Set up the headers for the request\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "}\n",
        "\n",
        "# Set up the request payload\n",
        "payload = {\n",
        "    \"contents\": [{\n",
        "        \"parts\": [{\n",
        "            \"text\": transcription_text\n",
        "        }]\n",
        "    }]\n",
        "}\n",
        "\n",
        "# Construct the URL with your API key\n",
        "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "# Make the request to Gemini API\n",
        "response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "# Check the response status and print the result\n",
        "if response.status_code == 200:\n",
        "    response_data = response.json()\n",
        "    # Assuming the response contains the generated content in a field like 'generatedContent'\n",
        "    summary = response_data.get('generatedContent', 'No summary available')\n",
        "    print(f\"Summary: {summary}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")\n",
        "\n",
        "# Check the response status and print the full response\n",
        "if response.status_code == 200:\n",
        "    response_data = response.json()\n",
        "    print(\"Full Response:\", json.dumps(response_data, indent=4))  # Print the entire response\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}, {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfSnW2CtONht",
        "outputId": "2bfa818f-709f-47ab-df15-f9e7ade9d1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: No summary available\n",
            "Full Response: {\n",
            "    \"candidates\": [\n",
            "        {\n",
            "            \"content\": {\n",
            "                \"parts\": [\n",
            "                    {\n",
            "                        \"text\": \"This is a comprehensive roadmap for becoming a DevOps engineer. Here's a summary organized for clarity, along with some observations:\\n\\n**Roadmap Summary:**  This plan suggests a 10-14 month timeline, assuming 3-5 hours of daily study.\\n\\n**Phase 1: Foundational Skills (6-8 weeks)**\\n\\n* **Linux Fundamentals (2-3 weeks):** Learn bash scripting, basic commands (file system, permissions, processes, package management).\\n* **Networking (2 weeks):** IP addressing, protocols (TCP/IP, HTTP, HTTPS, FTP, SSH), DNS, DHCP, firewalls, basic troubleshooting (ping, traceroute, netstat).  Wireshark recommended for hands-on experience.\\n* **Git (1-2 weeks):** Version control \\u2013 cloning, committing, pushing, pulling, branching, merging, conflict resolution.\\n\\n**Phase 2: Programming and Cloud (10-12 weeks)**\\n\\n* **Python (4-6 weeks):** Syntax, data structures (lists, dictionaries, sets, tuples), modules, packages, file handling, error handling, scripting, automation.\\n* **Cloud Provider (AWS - 4-6 weeks):**  Focus on one provider (AWS recommended). Learn virtual server management, data storage, user/group management, networking setup.\\n\\n**Phase 3: Containerization and CI/CD (7-8 weeks)**\\n\\n* **Docker (3-4 weeks):** Image creation, container management, Dockerfiles, multi-container applications (Docker Compose).\\n* **CI/CD (Jenkins - 3-4 weeks):** Pipeline creation, Jenkinsfiles, automated testing integration, automated build and deployment.\\n\\n**Phase 4: Orchestration and Management (10-12 weeks)**\\n\\n* **Kubernetes (4-6 weeks):** Architecture (master/worker nodes), pods, services, deployments, resource management, scaling.\\n* **Networking & Infrastructure Services (3-4 weeks):**  Reverse proxies (Nginx), load balancing (Nginx), caching, firewalls.\\n* **Configuration Management (Ansible - 3-4 weeks):** Writing playbooks, roles, modules, variable management, templating.\\n\\n**Phase 5: Infrastructure as Code and Monitoring (6-8 weeks)**\\n\\n* **Infrastructure as Code (Terraform - 3-4 weeks):** Providers, resources, configuration files, modules, workspaces, remote state.\\n* **Monitoring & Logging (Prometheus, Grafana - 3-4 weeks):** Architecture, metric collection, querying, alerting.\\n\\n**Observations and Recommendations:**\\n\\n* **Hands-on Practice:** The roadmap emphasizes learning concepts, but *practical experience* is crucial.  Build personal projects throughout the learning process to solidify your understanding.  Contribute to open-source projects to gain real-world experience.\\n* **Focus and Depth:**  While the breadth is impressive, consider focusing on a subset of tools within each category initially. Mastering a few tools well is more valuable than superficial knowledge of many.\\n* **Realistic Timeline:** The 10-14 month timeframe is ambitious.  Adjust it based on your learning style and prior experience.  Some topics (like Kubernetes) require significant time to master.\\n* **Learning Resources:** The creator mentions supplemental PDFs and tutorials.  Leverage diverse learning resources (online courses, documentation, books) to reinforce your understanding.\\n* **Certifications:** Consider industry certifications (AWS Certified DevOps Engineer, etc.) to validate your skills and improve job prospects.\\n\\nThis roadmap provides a strong foundation. Remember to adapt it to your interests and career goals, focusing on hands-on projects and continuous learning.\\n\"\n",
            "                    }\n",
            "                ],\n",
            "                \"role\": \"model\"\n",
            "            },\n",
            "            \"finishReason\": \"STOP\",\n",
            "            \"avgLogprobs\": -0.16490096647496635\n",
            "        }\n",
            "    ],\n",
            "    \"usageMetadata\": {\n",
            "        \"promptTokenCount\": 1443,\n",
            "        \"candidatesTokenCount\": 766,\n",
            "        \"totalTokenCount\": 2209\n",
            "    },\n",
            "    \"modelVersion\": \"gemini-1.5-flash\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = response_data['candidates'][0]['content']['parts'][0]['text']\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B39QX8VO77a",
        "outputId": "51756ed7-2848-4804-d7f9-e9fa57675688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a comprehensive roadmap for becoming a DevOps engineer. Here's a summary organized for clarity, along with some observations:\n",
            "\n",
            "**Roadmap Summary:**  This plan suggests a 10-14 month timeline, assuming 3-5 hours of daily study.\n",
            "\n",
            "**Phase 1: Foundational Skills (6-8 weeks)**\n",
            "\n",
            "* **Linux Fundamentals (2-3 weeks):** Learn bash scripting, basic commands (file system, permissions, processes, package management).\n",
            "* **Networking (2 weeks):** IP addressing, protocols (TCP/IP, HTTP, HTTPS, FTP, SSH), DNS, DHCP, firewalls, basic troubleshooting (ping, traceroute, netstat).  Wireshark recommended for hands-on experience.\n",
            "* **Git (1-2 weeks):** Version control – cloning, committing, pushing, pulling, branching, merging, conflict resolution.\n",
            "\n",
            "**Phase 2: Programming and Cloud (10-12 weeks)**\n",
            "\n",
            "* **Python (4-6 weeks):** Syntax, data structures (lists, dictionaries, sets, tuples), modules, packages, file handling, error handling, scripting, automation.\n",
            "* **Cloud Provider (AWS - 4-6 weeks):**  Focus on one provider (AWS recommended). Learn virtual server management, data storage, user/group management, networking setup.\n",
            "\n",
            "**Phase 3: Containerization and CI/CD (7-8 weeks)**\n",
            "\n",
            "* **Docker (3-4 weeks):** Image creation, container management, Dockerfiles, multi-container applications (Docker Compose).\n",
            "* **CI/CD (Jenkins - 3-4 weeks):** Pipeline creation, Jenkinsfiles, automated testing integration, automated build and deployment.\n",
            "\n",
            "**Phase 4: Orchestration and Management (10-12 weeks)**\n",
            "\n",
            "* **Kubernetes (4-6 weeks):** Architecture (master/worker nodes), pods, services, deployments, resource management, scaling.\n",
            "* **Networking & Infrastructure Services (3-4 weeks):**  Reverse proxies (Nginx), load balancing (Nginx), caching, firewalls.\n",
            "* **Configuration Management (Ansible - 3-4 weeks):** Writing playbooks, roles, modules, variable management, templating.\n",
            "\n",
            "**Phase 5: Infrastructure as Code and Monitoring (6-8 weeks)**\n",
            "\n",
            "* **Infrastructure as Code (Terraform - 3-4 weeks):** Providers, resources, configuration files, modules, workspaces, remote state.\n",
            "* **Monitoring & Logging (Prometheus, Grafana - 3-4 weeks):** Architecture, metric collection, querying, alerting.\n",
            "\n",
            "**Observations and Recommendations:**\n",
            "\n",
            "* **Hands-on Practice:** The roadmap emphasizes learning concepts, but *practical experience* is crucial.  Build personal projects throughout the learning process to solidify your understanding.  Contribute to open-source projects to gain real-world experience.\n",
            "* **Focus and Depth:**  While the breadth is impressive, consider focusing on a subset of tools within each category initially. Mastering a few tools well is more valuable than superficial knowledge of many.\n",
            "* **Realistic Timeline:** The 10-14 month timeframe is ambitious.  Adjust it based on your learning style and prior experience.  Some topics (like Kubernetes) require significant time to master.\n",
            "* **Learning Resources:** The creator mentions supplemental PDFs and tutorials.  Leverage diverse learning resources (online courses, documentation, books) to reinforce your understanding.\n",
            "* **Certifications:** Consider industry certifications (AWS Certified DevOps Engineer, etc.) to validate your skills and improve job prospects.\n",
            "\n",
            "This roadmap provides a strong foundation. Remember to adapt it to your interests and career goals, focusing on hands-on projects and continuous learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests googlesearch-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D-2dRBFQGy2",
        "outputId": "ad2359da-b005-4def-cc69-f55453d0793a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.2.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\n",
            "Downloading googlesearch_python-1.2.5-py3-none-any.whl (4.8 kB)\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from googlesearch import search\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Define a function to search the web if the answer isn't in the video content\n",
        "def web_search(query):\n",
        "    print(\"Searching the web for:\", query)\n",
        "    search_results = search(query, num_results=3)\n",
        "    return search_results\n",
        "\n",
        "# Define a function to interact with the Gemini API\n",
        "def fetch_summary_from_gemini(title, description, transcription, question):\n",
        "    # Combine the video information into one large text\n",
        "    video_content = f\"Title: {title}\\nDescription: {description}\\nTranscription: {transcription}\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "\n",
        "        if summary and question.lower() in summary.lower():  # Check if the question is answered in the video content\n",
        "            return summary\n",
        "        else:\n",
        "            # If not found in the video content, search the web\n",
        "            web_results = web_search(question)\n",
        "            return f\"Answer not found in the video content. Here's what I found on the web:\\n{web_results[0]}\"\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: Title, description, transcription, and a question\n",
        "title = \"The_Complete_DevOps_Roadmap\"\n",
        "description = \"\"\"\n",
        " Go from zero to a DevOps Engineer in 10-14 months. This step-by-step roadmap covers the essential skills you need to become a DevOps Engineer in 2024.\n",
        "\n",
        "❤️ Join this channel to get access to perks:\n",
        "https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA/join\n",
        "\n",
        "Download the FREE roadmap PDF here: https://mosh.link/devops-roadmap\n",
        "\n",
        "✋ Stay connected\n",
        "\n",
        "- Complete courses: https://codewithmosh.com\n",
        "- Twitter: https://twitter.com/moshhamedani\n",
        "- Facebook: https://www.facebook.com/programmingwithmosh/\n",
        "- Instagram: https://www.instagram.com/codewithmosh.official/\n",
        "- LinkedIn: https://www.linkedin.com/school/codewithmosh/\n",
        "\n",
        "📚 Tutorials\n",
        "\n",
        "https://youtu.be/_uQrJ0TkZlc?si=ZhlCrQs1SkaPNVa8\n",
        "https://youtu.be/8JJ101D3knE?si=OGTuS35LQqSunuhh\n",
        "https://youtu.be/pTFZFxd4hOI?si=DkijlBq9w076bm2l\n",
        "\n",
        "📖 Chapters\n",
        "\n",
        "00:00 - Introduction\n",
        "00:25 - Linux Fundamentals\n",
        "00:59 - Networking Concepts\n",
        "01:38 - Git\n",
        "02:03 - Programming Languages\n",
        "03:03 - Cloud Providers\n",
        "03:36 - Containerization\n",
        "04:04 - Continuous Integration/Continuous Deployment (CI/CD)\n",
        "04:51 - Container Orchestration\n",
        "05:28 - Networking & Infrastructure Services\n",
        "06:00 - Configuration Management\n",
        "06:26 - Infrastructure as Code (IaC)\n",
        "07:04 - Monitoring & Logging\n",
        "\n",
        "#devops\n",
        "\"\"\"\n",
        "transcription = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "question = \"What is the timeline to become a DevOps Engineer?\"\n",
        "\n",
        "# Get the chatbot's response\n",
        "response = fetch_summary_from_gemini(title, description, transcription, question)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "tPfQN8keQnTT",
        "outputId": "8d3faa97-cff3-48f3-8dc5-326a859bd48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the web for: What is the timeline to become a DevOps Engineer?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'generator' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a2df223f2bf1>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Get the chatbot's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_summary_from_gemini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m# Output the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-a2df223f2bf1>\u001b[0m in \u001b[0;36mfetch_summary_from_gemini\u001b[0;34m(title, description, transcription, question)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# If not found in the video content, search the web\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mweb_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweb_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Answer not found in the video content. Here's what I found on the web:\\n{web_results[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Error: {response.status_code}, {response.text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from googlesearch import search\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "# Define a function to search the web if the answer isn't in the video content\n",
        "def web_search(query):\n",
        "    print(\"Searching the web for:\", query)\n",
        "    search_results = list(search(query, num_results=3))  # Convert the generator to a list\n",
        "    return search_results\n",
        "\n",
        "# Define a function to interact with the Gemini API\n",
        "def fetch_summary_from_gemini(title, description, transcription, question):\n",
        "    # Combine the video information into one large text\n",
        "    video_content = f\"Title: {title}\\nDescription: {description}\\nTranscription: {transcription}\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "\n",
        "        if summary and question.lower() in summary.lower():  # Check if the question is answered in the video content\n",
        "            return summary\n",
        "        else:\n",
        "            # If not found in the video content, search the web\n",
        "            web_results = web_search(question)\n",
        "            return f\"Answer not found in the video content. Here's what I found on the web:\\n{web_results[0]}\"\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: Title, description, transcription, and a question\n",
        "title = \"The_Complete_DevOps_Roadmap\"\n",
        "description = \"\"\"\n",
        "Go from zero to a DevOps Engineer in 10-14 months. This step-by-step roadmap covers the essential skills you need to become a DevOps Engineer in 2024.\n",
        "\n",
        "❤️ Join this channel to get access to perks:\n",
        "https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA/join\n",
        "\n",
        "Download the FREE roadmap PDF here: https://mosh.link/devops-roadmap\n",
        "\n",
        "✋ Stay connected\n",
        "\n",
        "- Complete courses: https://codewithmosh.com\n",
        "- Twitter: https://twitter.com/moshhamedani\n",
        "- Facebook: https://www.facebook.com/programmingwithmosh/\n",
        "- Instagram: https://www.instagram.com/codewithmosh.official/\n",
        "- LinkedIn: https://www.linkedin.com/school/codewithmosh/\n",
        "\n",
        "📚 Tutorials\n",
        "\n",
        "https://youtu.be/_uQrJ0TkZlc?si=ZhlCrQs1SkaPNVa8\n",
        "https://youtu.be/8JJ101D3knE?si=OGTuS35LQqSunuhh\n",
        "https://youtu.be/pTFZFxd4hOI?si=DkijlBq9w076bm2l\n",
        "\n",
        "📖 Chapters\n",
        "\n",
        "00:00 - Introduction\n",
        "00:25 - Linux Fundamentals\n",
        "00:59 - Networking Concepts\n",
        "01:38 - Git\n",
        "02:03 - Programming Languages\n",
        "03:03 - Cloud Providers\n",
        "03:36 - Containerization\n",
        "04:04 - Continuous Integration/Continuous Deployment (CI/CD)\n",
        "04:51 - Container Orchestration\n",
        "05:28 - Networking & Infrastructure Services\n",
        "06:00 - Configuration Management\n",
        "06:26 - Infrastructure as Code (IaC)\n",
        "07:04 - Monitoring & Logging\n",
        "\n",
        "#devops\n",
        "\"\"\"\n",
        "transcription = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "question = \"Should we build a strong fonudation in python?\"\n",
        "\n",
        "# Get the chatbot's response\n",
        "response = fetch_summary_from_gemini(title, description, transcription, question)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "59lZMTMQRWFn",
        "outputId": "a6f46a4b-f702-4442-a423-1c5f4211d08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the web for: Should we build a strong fonudation in python?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4fe4dafff5f8>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Get the chatbot's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_summary_from_gemini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Output the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-4fe4dafff5f8>\u001b[0m in \u001b[0;36mfetch_summary_from_gemini\u001b[0;34m(title, description, transcription, question)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# If not found in the video content, search the web\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mweb_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweb_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Answer not found in the video content. Here's what I found on the web:\\n{web_results[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Error: {response.status_code}, {response.text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from googlesearch import search\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Define a function to search the web if the answer isn't in the video content\n",
        "def web_search(query):\n",
        "    print(\"Searching the web for:\", query)\n",
        "    search_results = list(search(query, num_results=3))  # Convert the generator to a list\n",
        "    return search_results\n",
        "\n",
        "# Define a function to interact with the Gemini API\n",
        "def fetch_summary_from_gemini(title, description, transcription, question):\n",
        "    # Combine the video information into one large text\n",
        "    video_content = f\"Title: {title}\\nDescription: {description}\\nTranscription: {transcription}\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "\n",
        "        # Check if the question is directly answered in the video content\n",
        "        if summary and question.lower() in summary.lower():  # Check if the question is answered in the video content\n",
        "            return summary\n",
        "        else:\n",
        "            # If not found in the video content, search the web\n",
        "            web_results = web_search(question)\n",
        "            if web_results:\n",
        "                return f\"Answer not found in the video content. Here's what I found on the web:\\n{web_results[0]}\"\n",
        "            else:\n",
        "                return \"Sorry, I couldn't find any relevant results on the web.\"\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: Title, description, transcription, and a question\n",
        "title = \"The_Complete_DevOps_Roadmap\"\n",
        "description = \"\"\"\n",
        "Go from zero to a DevOps Engineer in 10-14 months. This step-by-step roadmap covers the essential skills you need to become a DevOps Engineer in 2024.\n",
        "\n",
        "❤️ Join this channel to get access to perks:\n",
        "https://www.youtube.com/channel/UCWv7vMbMWH4-V0ZXdmDpPBA/join\n",
        "\n",
        "Download the FREE roadmap PDF here: https://mosh.link/devops-roadmap\n",
        "\n",
        "✋ Stay connected\n",
        "\n",
        "- Complete courses: https://codewithmosh.com\n",
        "- Twitter: https://twitter.com/moshhamedani\n",
        "- Facebook: https://www.facebook.com/programmingwithmosh/\n",
        "- Instagram: https://www.instagram.com/codewithmosh.official/\n",
        "- LinkedIn: https://www.linkedin.com/school/codewithmosh/\n",
        "\n",
        "📚 Tutorials\n",
        "\n",
        "https://youtu.be/_uQrJ0TkZlc?si=ZhlCrQs1SkaPNVa8\n",
        "https://youtu.be/8JJ101D3knE?si=OGTuS35LQqSunuhh\n",
        "https://youtu.be/pTFZFxd4hOI?si=DkijlBq9w076bm2l\n",
        "\n",
        "📖 Chapters\n",
        "\n",
        "00:00 - Introduction\n",
        "00:25 - Linux Fundamentals\n",
        "00:59 - Networking Concepts\n",
        "01:38 - Git\n",
        "02:03 - Programming Languages\n",
        "03:03 - Cloud Providers\n",
        "03:36 - Containerization\n",
        "04:04 - Continuous Integration/Continuous Deployment (CI/CD)\n",
        "04:51 - Container Orchestration\n",
        "05:28 - Networking & Infrastructure Services\n",
        "06:00 - Configuration Management\n",
        "06:26 - Infrastructure as Code (IaC)\n",
        "07:04 - Monitoring & Logging\n",
        "\n",
        "#devops\n",
        "\"\"\"\n",
        "transcription = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "\n",
        "question = \"Should I start learning bash?\"\n",
        "\n",
        "# Get the chatbot's response\n",
        "response = fetch_summary_from_gemini(title, description, transcription, question)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGnGkOFoTwBD",
        "outputId": "7d68119b-1546-4737-86eb-804a220ad896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the web for: Should I start learning bash?\n",
            "Bot Response: Answer not found in the video content. Here's what I found on the web:\n",
            "https://www.reddit.com/r/linux/comments/2vx1bu/is_it_worth_is_to_learn_bash/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from googlesearch import search\n",
        "\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Function to search the web if answer isn't found in the video content\n",
        "def web_search(query):\n",
        "    print(\"Searching the web for:\", query)\n",
        "    search_results = list(search(query, num_results=3))  # Convert the generator to a list\n",
        "    return search_results\n",
        "\n",
        "# Function to interact with the Gemini API\n",
        "def fetch_summary_from_gemini(title, description, transcription, question):\n",
        "    # Preprocess transcription: Ask Gemini to clean and summarize the transcription\n",
        "    cleaned_transcription = f\"Clean the following transcription and summarize it to find relevant answers for questions:\\n{transcription}\"\n",
        "    print(cleaned_transcription)\n",
        "\n",
        "    # Combine the video information into one large text\n",
        "    video_content = f\"Title: {title}\\nDescription: {description}\\nTranscription: {cleaned_transcription}\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "\n",
        "        # Check if the question is directly answered in the cleaned-up transcription\n",
        "        if summary and question.lower() in summary.lower():\n",
        "            return summary\n",
        "        else:\n",
        "            # If not found in the video content, search the web\n",
        "            web_results = web_search(question)\n",
        "            if web_results:\n",
        "                return f\"Answer not found in the video content. Here's what I found on the web:\\n{web_results[0]}\"\n",
        "            else:\n",
        "                return \"Sorry, I couldn't find any relevant results on the web.\"\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input\n",
        "title = \"The_Complete_DevOps_Roadmap\"\n",
        "description = \"Go from zero to a DevOps Engineer in 10-14 months. This step-by-step roadmap covers the essential skills you need to become a DevOps Engineer in 2024.\"\n",
        "transcription = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash\"\"\"\n",
        "\n",
        "question = \"Is this video about becoming a devops engineer?\"\n",
        "\n",
        "# Get the chatbot's response\n",
        "response = fetch_summary_from_gemini(title, description, transcription, question)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQW8ZXc4U-Md",
        "outputId": "339c25e5-0240-4cc1-ef66-e972d5362c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean the following transcription and summarize it to find relevant answers for questions:\n",
            "if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash\n",
            "Searching the web for: Is this video about becoming a devops engineer?\n",
            "Bot Response: Sorry, I couldn't find any relevant results on the web.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#good\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Define the context that the model must use for answering questions\n",
        "context = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "\n",
        "# Define a function to interact with the Gemini API and answer questions based on the given context\n",
        "def fetch_answer_from_gemini(question, context):\n",
        "    # Combine the context with the question and instruct Gemini to answer based on it\n",
        "    video_content = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "        return summary\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: question based on your context\n",
        "question = \"Should I start learning bash?\"\n",
        "\n",
        "# Get the chatbot's response based on the provided context\n",
        "response = fetch_answer_from_gemini(question, context)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W94GpZFU-60",
        "outputId": "5082b080-60e9-4d8d-df7e-a030620ff1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot Response: Yes, the roadmap explicitly recommends starting with learning bash, as it's the most commonly used shell and scripting language in Linux.  It's considered crucial for anyone wanting to become a DevOps engineer.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Define the context that the model must use for answering questions\n",
        "context = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "\n",
        "# Define a function to interact with the Gemini API and answer questions based on the given context\n",
        "def fetch_answer_from_gemini(question, context):\n",
        "    # Combine the context with the question and instruct Gemini to answer based on it\n",
        "    video_content = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "        return summary\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: question based on your context\n",
        "question = \"Should I be strong at Java language?\"\n",
        "\n",
        "# Get the chatbot's response based on the provided context\n",
        "response = fetch_answer_from_gemini(question, context)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udG53tH0XbkL",
        "outputId": "0df5e194-e53c-4fc3-cbc4-b2dde702cfe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot Response: The provided roadmap does not mention Java as a required language.  It focuses on Python for programming language fundamentals.  While Java is a widely used language in software development, it's not explicitly listed as a necessary skill for breaking into DevOps according to this specific roadmap.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Define the context that the model must use for answering questions\n",
        "context = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "\n",
        "# Define a function to interact with the Gemini API and answer questions based on the given context\n",
        "def fetch_answer_from_gemini(question, context):\n",
        "    # Combine the context with the question and instruct Gemini to answer based on it\n",
        "    video_content = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "        return summary\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: question based on your context\n",
        "question = \"What is the timeline provided to become a devops engineer\"\n",
        "\n",
        "# Get the chatbot's response based on the provided context\n",
        "response = fetch_answer_from_gemini(question, context)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nuz4oH8XiBc",
        "outputId": "ddac1b7b-2c0f-4634-8279-aac175add531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot Response: The timeline provided to become a DevOps engineer, assuming 3-5 hours of study daily, is 10 to 14 months.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Replace with your actual Gemini API key\n",
        "API_KEY = 'AIzaSyBGRyPEB-v-cnhAgVhDXUd_6pcwyou7oFU'\n",
        "\n",
        "# Define the context that the model must use for answering questions\n",
        "context = \"\"\"if you're looking to break into devolves or want to level up your skills you're in the right place today i'm showing the complete their bops road map i'll walk you through their social skills you need that tools i personally recommend and how much time you should spend on each assuming you dedicate three to five hours of studying everyday this road map should take you about ten to four in months to complete this jump right in first off we have linux fundamentals linux is the backbone of servers and development environments as it develops engineer you'll be setting up and maintaining the infrastructure were applications rock most servers use linux so getting comfortable with it especially the command line is crucial i recommend starting with learn and bash which is the most commonly used shell and scripting language and linux spend about two to three weeks on this make sure to learn basic linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking concepts networking is all about how computers communicate with each other think ip address as and protocols you need to understand how data moves around secure it and troubleshoot network issues to get hands on experience i recommend using wire shark dedicate around two weeks on this make sure to learn concepts like was i anticipate ip models ip addressing and submit think dns and the hcp networking protocols like http https ftp an ssh firewalls and security groups and basic network troubleshooting using tools like paying trace route and nets that now let's talk about get get as a version control system that lets you track changes in your code and collaborate with others is essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone comment push and pull branching and merging resolving merge conflicts working with remote repositories and so on after that you should dive into programming languages programming languages like python ruby and go are used to automate tasks and manage configurations why there are several other languages i personally recommend python for it's simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in python make sure to learn python syntax and data structures like lists dictionaries sets and topples modules and packages learn how to write and execute python scripts worked with files handle errors right automation scripts and saw by the way to help you on this journey of created a free supplementary pdf that breaks down specific concepts you need to learn for each skill it's a great resource to reveal your progress find gaps you know knowledge and prepare for interviews you can find a lake and the description box also i have a bunch of tutorials on his channel and complete courses on my website if you're looking for a structure learning again links are in the description box moving on let's talk about cloud providers cloud providers like a w s as your and google cloud platform offer a range of services for building and deploying applications if you're just starting out i recommend focusing on one cloud provider and a w s is a great choice because is the most widely used spent about four to six weeks on this make sure to la learn how to launch configure and managed virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is container ization container is a son is all about packaging application and it's dependencies into container to ensure it runs to say same everywhere docker is the go to tool for this spent about three to four weeks getting comfortable with docker learn how to create docker images get familiar with starting stopping and managing containers learn how to write docker files explore how to define and run multi container applications using docker compose and so on now diving to continuous integration and deployment or see i see the see i see the automate the integration and deployment of code changes allowing for frequent and reliable release as jenkins is a powerful tool for setting up see i see the pipeline's but other popular tools include get lap see i see the circle cia and travesty i if you're starting out just focus on jenkins for it's versatility and strong community support dedicate three to four weeks on this make sure to understand how to create and manage jenkins pipelines get familiar with writing jenkins files learn how to integrate automated tests into your pipelines understand how to automate the built price as for your applications explore how to automate the deployment of your applications to various environments and swat moving forward let's discuss orchestration and management orchestration tools like coburn it is and helm have automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with cornelius and span about four to six weeks on it make sure to learn about the overall architecture including the master node and worker note and how they interact understand the key components such as pods services and deployments get familiar with managing resources learned how to scale your application just as well as the network and model in corny these next we have networking and infrastructure services this involves setting up and managing services like reverse proxy as forward proxies caching servers firewalls and load balancers i recommend using engine x for handling reverse proxies and load balancing give this above three to four weeks of your time learn how to set up and configure engine acts as a reverse proxy and understand how to configure it to act as a forward proxy explore caching strategy is to improve the performance and how to configure firewalls and security groups now let's talk about configuration management configuration management tools like answer ball pop out and chef automate the deployment configuration and management of servers and applications if you're starting out just focus on and a book due to it's simplicity and powerful features spent three to four weeks on this learn how to write and zibel playbooks understand how to use roles and modules learn to manage variables and template and saw moving on let's discuss infrastructure as code or i see i seen was managing and provisioning computing infrastructure through a machine readable conflagration fights popular tools include terraform a ws cloud formation and for leumi if you're starting out just focus on terraform for it's flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files to learn how to use terraform modules as well as advanced concepts such as workspace as and remote state finally let's talk about monitoring and logging monitoring and logging tools such as promised the us grow fauna he okay stack and flynn the track the performance and half of your applications and infrastructure if you're starting out just focus on prom if the us and grow fauna span about three to four weeks on these tools learn to architecture and data model of prom if the us get familiar with collecting metrics from various sources learn how to read quarries to extract and allies metric state don't understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a dev engineer in about ten to fourteen months if you have any questions please let me know in the comments below and i'll do my best to answer you right here or in my future videos if you enjoyed this video please give the like and subscribe for more useful content thanks for watching \"\"\"\n",
        "\n",
        "# Define a function to interact with the Gemini API and answer questions based on the given context\n",
        "def fetch_answer_from_gemini(question, context):\n",
        "    # Combine the context with the question and instruct Gemini to answer based on it\n",
        "    video_content = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "    # Set up the headers and payload for the request to Gemini\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"contents\": [{\n",
        "            \"parts\": [{\"text\": video_content}]\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    # Send the request to Gemini\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}\"\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        response_data = response.json()\n",
        "        summary = response_data.get('candidates', [])[0].get('content', {}).get('parts', [])[0].get('text', '')\n",
        "        return summary\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "# Example input: question based on your context\n",
        "question = \"What is this youtubers name\"\n",
        "\n",
        "# Get the chatbot's response based on the provided context\n",
        "response = fetch_answer_from_gemini(question, context)\n",
        "\n",
        "# Output the response\n",
        "print(\"Bot Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPsOOu6vYyBp",
        "outputId": "87666ce1-9732-49af-f1da-d57c9da4643f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot Response: The YouTuber's name is not explicitly mentioned in the provided text.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SpeechRecognition keybert ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THexZZYzc0Rd",
        "outputId": "c032bcaa-131d-422a-c171-112efa2cc89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.14.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from keybert) (1.6.0)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from keybert) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.12.14)\n",
            "Downloading SpeechRecognition-3.14.0-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=d5e7c92c5eac87c5eaaa32aae2c6db19aaf34a3146af07b9c59fd4f898f27106\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg, SpeechRecognition, keybert\n",
            "Successfully installed SpeechRecognition-3.14.0 ffmpeg-1.4 keybert-0.8.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "from keybert import KeyBERT\n",
        "import math\n",
        "\n",
        "# File path for the audio file\n",
        "audio_path = '/content/The_Complete_DevOps_Roadmap.mp3'\n",
        "\n",
        "# Load the audio file using pydub\n",
        "audio = AudioSegment.from_mp3(audio_path)\n",
        "\n",
        "# Create the recognizer for speech-to-text\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Create KeyBERT model instance\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Function to split audio into segments (2 minutes each)\n",
        "def split_audio(audio, segment_length=2 * 60 * 1000):  # 2 minutes in milliseconds\n",
        "    segments = []\n",
        "    total_duration = len(audio)\n",
        "    num_segments = math.ceil(total_duration / segment_length)\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * segment_length\n",
        "        end_time = min((i + 1) * segment_length, total_duration)\n",
        "        segment = audio[start_time:end_time]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "# Function to transcribe audio to text using Google Speech Recognition\n",
        "def transcribe_audio(segment):\n",
        "    with sr.AudioFile(segment) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            return None\n",
        "        except sr.RequestError:\n",
        "            return None\n",
        "\n",
        "# Function to extract key phrases using KeyBERT\n",
        "def extract_keywords(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
        "    return [keyword[0] for keyword in keywords]\n",
        "\n",
        "# Split the audio into segments\n",
        "segments = split_audio(audio)\n",
        "\n",
        "# Timeline and segment keyword extraction\n",
        "timeline = []\n",
        "for i, segment in enumerate(segments):\n",
        "    # Export the segment to a temporary file\n",
        "    temp_segment_path = f\"/content/temp_segment_{i}.wav\"\n",
        "    segment.export(temp_segment_path, format=\"wav\")\n",
        "\n",
        "    # Transcribe the audio segment\n",
        "    transcription = transcribe_audio(temp_segment_path)\n",
        "\n",
        "    if transcription:\n",
        "        # Extract keywords for the transcription\n",
        "        keywords = extract_keywords(transcription)\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",  # 2-minute intervals\n",
        "            \"keywords\": keywords,\n",
        "            \"transcription\": transcription\n",
        "        })\n",
        "    else:\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",\n",
        "            \"keywords\": [],\n",
        "            \"transcription\": \"Could not transcribe audio\"\n",
        "        })\n",
        "\n",
        "    # Clean up the temporary file\n",
        "    os.remove(temp_segment_path)\n",
        "\n",
        "# Output the timeline\n",
        "for segment in timeline:\n",
        "    print(f\"Timestamp: {segment['timestamp']}\")\n",
        "    print(f\"Transcription: {segment['transcription']}\")\n",
        "    print(f\"Keywords: {segment['keywords']}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4fcab6ab122c4cee9cad374995460022",
            "917f8b2a28ac44079d4387e00688d63c",
            "fa60595bb47f4803ad0f0678c510961e",
            "acc41e0c9718469aa9ece362c8901a16",
            "a3f3e23470b44844bab105c9bcc4f26d",
            "5066f0725c0a4aacb9f2e98e97ed81df",
            "b4fa4c1e5af6442db0415b872befd5eb",
            "a1d90375d1e545078146680bc91431e2",
            "fc4d08234ef54857b8a7ecc2970c329f",
            "60aabf5ea0484c01a2be35175546ee72",
            "1650684691ef46b4a2ee644ebd237f3b",
            "2ea406fe3e4240c3894978ac673b6353",
            "1a65279a25854538828619643c420719",
            "e901bf3a82cb4b0c81c5a152136b5aaa",
            "cf934b1737804f5ea258e19e8f38b19a",
            "901c282d69dc48c58749b0f332ac4a2f",
            "0d52a270c7cb424cb37395c4b9f8f821",
            "4a274ea8289b40469dfc9caac66c56f2",
            "d4d45027d3974c6ab3eb8c0de315d7f8",
            "8d7a0d91250a48fc88f53700c7418a7e",
            "a2eeaad500a34213a0d541f26e74b4c0",
            "650547cf756e4fc9bcb361bd27acd2af",
            "1075f63c7dca49d3bb1777e933f88dc9",
            "93c5027ce2b747e38e022aea5facef9e",
            "c5f0fa2c6d29419e8c2ba5d46a33463c",
            "1cab80038c774e3b8a8e5a881e79d5f5",
            "ce973dd5f7714fd693bf2b76f2a24092",
            "7b4684a1e1e44769ac0afc87216554df",
            "f4b4df8cead448018df8ea3556a49876",
            "c2dcdbb001ca416384210ac5fe64592a",
            "4642a22af27b48a5834921ba3ad58dd2",
            "8f7ee41f5af644d89ef7635baa4cfa1e",
            "2d515385903e491ca64dd97cc9b43968",
            "50f9b8dcdf0e4a3a9cf4900d94c83ef7",
            "d159094afb9d4a43b54d189cb11e7d25",
            "a6a4ec35ef574e598acd3d27035d6648",
            "8ea6a979527f4f5e8eede26c1112c8d5",
            "4d25bd6b12fc40c0b03df1d3f401f6d4",
            "69e793d9426b4716bcab02de2ba05ba4",
            "129c2764533749518e77aa148ccdf54c",
            "b06686463ae74e0bb0db1048965420f3",
            "3cd97f94133842c4881168290f7c57cb",
            "f7406a17bd414e45aec1ef5940b00e4f",
            "6c2e25d6bdbd4351a3fccf6b4ac354e4",
            "dcc6d360bc174717874008835b19c9ab",
            "8bb84b352ccc44c5b7a532ec215646d6",
            "77a42355edb2441fa11427dacb54543e",
            "cf6cbc13cdb44cfe999f0e59bb4499f5",
            "5b4b54783f1441f892ed8c2bbd2e7c2b",
            "f334a6768ba94b13814837a87ab92f47",
            "2f94928bae21404da692f1f2bd12a16e",
            "c7acb680de194fcfaded99d6faf82175",
            "6ed1dcf1aaa44384af28587593c755f6",
            "d9b7c13ef7764cf3a2579fb3da5d6645",
            "7ccc9a6ad6e94ae0be453796e9512830",
            "6cb0d0764af5404d936544ce4eed23d8",
            "973ff65359164a16a382f8512df82040",
            "2639f2bad946495aa1434c66acafc2f4",
            "234c87b809844265889d0d611f1ca805",
            "4b6623fa8d8949d1a30832bbf3c515a6",
            "20126b56372d4c239769d977819c9f22",
            "b0ba77817749459fa30db8090924e490",
            "27f68c00d65b407a95b6ad19158b29c7",
            "5fc210866ced45b882f4467418062a00",
            "c0fa8bc59d504ab0af858d22bd719417",
            "d8d9f9a8e4ec4e9aa15ec4711464de4f",
            "a5dceecdc1f840b795b591d455989600",
            "285ec321793d49ddb323cbcddd4a87bc",
            "309a514ae6494013962fae419d78f6ef",
            "564f96bd17be422fb4b321b934e69a6b",
            "3b7fdf075e39432784421ba2826bc4ec",
            "79bf21db6fe54bedbf4faee4baf0c16c",
            "51a13b64753a40c69dda8ebe54247144",
            "0cf108f5b897436f99589bf9025c9f99",
            "72a3ca3a6ced4da5b0f39491f58622ae",
            "bd268b5343c34999b39ea232325bcd85",
            "e02912630a514289a1ae347e3c94cd41",
            "bb95848df464402a9dbdf66424f341a7",
            "80623a3d7aaa43b59a5cbfd8fa727656",
            "5b6d8f485aac4ac799e20cb8bdf005ec",
            "d11ff4f9c357480b932015f908a207a0",
            "02f58273c357445f95931588500a49d8",
            "e4a1c71dd4f44ea5af44d17737aa7156",
            "02308ab1898b4f7ba22b20d3654d9bca",
            "cce9b2d3740c4b1287bb4bf08e0b3568",
            "3961eb2137754e51bd3b23a3cfe8a0a0",
            "b70a04c499ba431ba13dc2cc7a989974",
            "efe50dd91ae845478fabebdce3246e9e",
            "c3361a02509744f9bd279c56df1ded85",
            "c88ad1e272874a72bd4e3cbf503d833e",
            "130caa04affa4a98bfb6b066d9b8d1ab",
            "291ec2a111f44ec885472bd56525995b",
            "56e5217ae52d4a5ba6ba784bd2dd45d0",
            "cd22a2a7af524e05b71dcb6ad8905d85",
            "ef488f291bb840fcab5c1bab95b5b451",
            "0b4f2a8238594691876d3655f98ccb50",
            "d0318bd3f144451c91d9a8623ed2a727",
            "939ce606f918479fad595d154196d8da",
            "d482478294d04995a4282db976a103aa",
            "f21909005eb244cfbd3f0414851d6dea",
            "30c71d500a134c3a95d09f17c468bef6",
            "e5d86fbcc42e4a74a210c4c6f111fa12",
            "67546c8dd53248bab73e06ddb74cbc8f",
            "024b20157d1d48d584e509113139ae43",
            "b36bf13fefa04a67af39a5e69a4d8e3d",
            "035e36198f4f446bb68af830e2897f17",
            "f776fd5c153a4e79888446fdba49aeaa",
            "79692437fde04393828ea52eb74e3e6e",
            "0b955914ac4b4b61a06998713cc4845e",
            "3f2580ae7a824c87b6e408b880aba7cf",
            "f0a00b73ace544a2afb3746675253824",
            "0df94fea681a4473bc91de42ae75c3c2",
            "83b5b51e8ce743e9aa101336b63fc496",
            "732cf5c4255f4f998856b13594360bce",
            "403c9ed14003491e82999d7686e7cc57",
            "fd130972affd47e4be57f8d6f552dced",
            "3a90c25537344c10bc4ce6d957daaad7",
            "9296a80244fb4b9f9f6fae3027c6a421",
            "1e8efb512d844f08a001939b3428eef9",
            "10d94e23e6634cb09bec388df579d1f3",
            "4f06310640df44c8a9b2a67c8abb976f"
          ]
        },
        "id": "5sGe1vRGc0U-",
        "outputId": "288acd46-9ef6-4d49-eb06-0404b8e89edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fcab6ab122c4cee9cad374995460022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ea406fe3e4240c3894978ac673b6353"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1075f63c7dca49d3bb1777e933f88dc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50f9b8dcdf0e4a3a9cf4900d94c83ef7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcc6d360bc174717874008835b19c9ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb0d0764af5404d936544ce4eed23d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5dceecdc1f840b795b591d455989600"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb95848df464402a9dbdf66424f341a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3361a02509744f9bd279c56df1ded85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f21909005eb244cfbd3f0414851d6dea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0a00b73ace544a2afb3746675253824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 0 - 2 minutes\n",
            "Transcription: if you're looking to break into devops or want to level up your skills you're in the right place today I'm sharing the complete devops roadmap I'll walk you through the essential skills you need the tools I personally recommend and how much time you should spend on each assuming you're dedicate three to five hours of studying everyday this road map should take you about 10 to 14 months to complete let's Jump Right In first off we have Linux fundamentals Linux is the background of servers and development environments as a devops engineer you'll be setting up and maintaining the infrastructure where applications run most servers use Linux so getting comfortable with it especially the command line is crucial I recommend starting with learning bash which is the most commonly used shell and scripting language in Linux spend about two to three weeks on this make sure to learn basic Linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to learn networking Concepts networking is all about how computers communicate with each other think IP addresses and protocols you need to understand how data moves around secured and troubleshoot network issues to get hands-on experience I recommend using Wireshark dedicate around 2 weeks on this make sure to learn Concepts like OSI and tcpip models IP addressing and subnetting DNS and DHCP networking protocols like HTTP https FTP and SSH firewalls and security groups and basic Network troubleshooting using tools like pink trace route and netstat now let's talk about get is a version control system that lets you track changes in your code and collaborate with others it's essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like clone commitment for branching and merging resulting merch\n",
            "Keywords: ['devops roadmap', 'devops engineer', 'linux fundamentals', 'fundamentals linux', 'complete devops']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 2 - 4 minutes\n",
            "Transcription: play working with remote repositories and so on after that you should dive into programming languages programming languages like python Ruby and go are used to automate tasks and manage configurations while there are several other languages I personally recommend python for its Simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in Python make sure to Learn Python syntax and data structures like lists dictionaries sets on topples modules and packages learn how to write and execute Python scripts work with files handle errors right automation scripts and so on by the way to help you on this journey of created a free supplementary PDF that breaks down the specific Concepts you need to learn for each skill it's a great resource to review your progress find gaps in your knowledge and prepare for interviews you can find the link in the description box also I have a bunch of tutorials on this channel and complete courses on my website if you are looking for structured learning again links are in the description box moving on let's talk about Cloud providers Cloud providers like AWS Azure and Google Cloud platform offer a range of services for building and deploying applications if you're just starting out I recommend focusing on one cloud provider and AWS is a great choice because it's the most widely used span about 4 to 6 weeks on this make sure to learn how to launch configure and manage virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is containerization containerization is all about packaging an application and its dependencies into container to ensure it runs the same everywhere Docker is the go to tool for this span about 3 to 4 weeks getting comfortable with Docker learn how to create Docker images get familiar with starting stopping and managing containers learn how to write Docker files Explorer how to define and run\n",
            "Keywords: ['learn python', 'recommend python', 'programming', 'tutorials', 'python ruby']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 4 - 6 minutes\n",
            "Transcription: multi container applications using Docker compose and so on now let's dive into continuous integration and deployment or cicd cicd Artemis the integration and deployment of code changes allowing for frequent and reliable releases Jenkins is a powerful tool for setting up Ci City pipelines but other popular tools include gitlab cicd Circle C i and Travis CI if you're starting out just focus on Jenkins for its versatility and strong Community Support dedicate three to four weeks on this make sure to understand how to create and manage Jenkins pipelines get familiar with writing Jenkins files learn how to integrate automated tests into your pipelines understand how to automate the build process for your applications Explorer how to automate the deployment of your applications to various environments and Swan moving forward let's discuss orchestration and management orchestration tools like kubernetes and Helm Health automate the deployment scaling and management of containerized applications these tools are essential for managing complex applications in production start with kubernetes and span about 4 to 6 weeks on it make sure to learn about the overall architecture including the master known and worker notes and how they interact understanding the key components such as pods services and deployments get familiar with management resources learn how to scale your applications as well as the networking model in kubernetes next we have networking and infrastructure services this involves setting up and managing services like reverse proxies forward proxies cashing service and load balances I recommend using nginx for handling reverse proxies and load balancing if this about three to four weeks of your time learn how to set up and configure engine X as a reverse proxy on Sunday how to configure it to act as a forward proxy Explorer cashing strategies to improve the performance and how to configure firewalls and\n",
            "Keywords: ['jenkins pipelines', 'container applications', 'management containerized', 'containerized applications', 'jenkins versatility']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 6 - 8 minutes\n",
            "Transcription: now let's talk about configuration management configuration management tools like ansible puppet and Chef automate the deployment configuration and management of servers and applications if you're starting out just focus on ansible due to its Simplicity and Powerful features spent 3 to 4 weeks on this learn how to write ansible Play Books understand how to use roles and modules learn to manage variables and templates and so on moving on let's discuss our code or IAC I see in managing and provisioning infrastructure through machine readable configuration files popular tools include terraform AWS cloudformation and pelumi if you're starting out just focus on terraform for its flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files learn how to use terraform modules as well as advanced concepts such as workspace as and remote finally let's talk about monitoring and logging monitoring and logging tools such as promises grafana elk and flu track the performance and health of your applications and infrastructure if you're starting out just focus on promises and grafana about three to four weeks on these tools learn the architecture and data model of Prometheus get familiar with collecting metrics from various sources learn how to write queries to extract and analyze metrics data on how to set up alerts and Swan so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a devops engineer in about 10 to 14 months if you have any questions please let me know in the comments below and I'll do my best to answer you right here or in my future videos If you enjoyed this video please give me the like And subscribe for more content thanks for watching\n",
            "Keywords: ['terraform configuration', 'terraform aws', 'terraform modules', 'use terraform', 'terraform understand']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 8 - 10 minutes\n",
            "Transcription: Could not transcribe audio\n",
            "Keywords: []\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "from keybert import KeyBERT\n",
        "import math\n",
        "\n",
        "# File path for the audio file\n",
        "audio_path = '/content/The_Complete_DevOps_Roadmap.mp3'\n",
        "\n",
        "# Load the audio file using pydub\n",
        "audio = AudioSegment.from_mp3(audio_path)\n",
        "\n",
        "# Create the recognizer for speech-to-text\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Create KeyBERT model instance\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Function to split audio into segments (2 minutes each)\n",
        "def split_audio(audio, segment_length= 60 * 1000):  # 2 minutes in milliseconds\n",
        "    segments = []\n",
        "    total_duration = len(audio)\n",
        "    num_segments = math.ceil(total_duration / segment_length)\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * segment_length\n",
        "        end_time = min((i + 1) * segment_length, total_duration)\n",
        "        segment = audio[start_time:end_time]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "# Function to transcribe audio to text using Google Speech Recognition\n",
        "def transcribe_audio(segment):\n",
        "    with sr.AudioFile(segment) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            return None\n",
        "        except sr.RequestError:\n",
        "            return None\n",
        "\n",
        "# Function to extract the top keyword using KeyBERT\n",
        "def extract_top_keyword(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
        "    # Return only the top keyword (the first one with the highest score)\n",
        "    return keywords[0][0] if keywords else None\n",
        "\n",
        "# Split the audio into segments\n",
        "segments = split_audio(audio)\n",
        "\n",
        "# Timeline and segment keyword extraction\n",
        "timeline = []\n",
        "for i, segment in enumerate(segments):\n",
        "    # Export the segment to a temporary file\n",
        "    temp_segment_path = f\"/content/temp_segment_{i}.wav\"\n",
        "    segment.export(temp_segment_path, format=\"wav\")\n",
        "\n",
        "    # Transcribe the audio segment\n",
        "    transcription = transcribe_audio(temp_segment_path)\n",
        "\n",
        "    if transcription:\n",
        "        # Extract the top keyword for the transcription\n",
        "        top_keyword = extract_top_keyword(transcription)\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",  # 2-minute intervals\n",
        "            \"keyword\": top_keyword,\n",
        "            \"transcription\": transcription\n",
        "        })\n",
        "    else:\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",\n",
        "            \"keyword\": None,\n",
        "            \"transcription\": \"Could not transcribe audio\"\n",
        "        })\n",
        "\n",
        "    # Clean up the temporary file\n",
        "    os.remove(temp_segment_path)\n",
        "\n",
        "# Output the timeline\n",
        "for segment in timeline:\n",
        "    print(f\"Timestamp: {segment['timestamp']}\")\n",
        "    print(f\"Transcription: {segment['transcription']}\")\n",
        "    print(f\"Keyword: {segment['keyword']}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnPwgd7ceFm6",
        "outputId": "9a531b0b-7589-40fd-a066-42baf9af8629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 0 - 2 minutes\n",
            "Transcription: if you're looking to break into devops or want to level up your skills you're in the right place today I'm sharing the complete devops roadmap I'll walk you through the essential skills you need the tools I personally recommend and how much time you should spend on each assuming you're dedicate three to five hours of studying everyday this road map should take you about 10 to 14 months to complete let's Jump Right In first off we have Linux fundamentals Linux is the background of servers and development environments as a devops engineer you'll be setting up and maintaining the infrastructure where applications run most servers use Linux so getting comfortable with it especially the command line is crucial I recommend starting with learning bash which is the most commonly used shell and scripting language in Linux spend about two to three weeks on this make sure to learn basic Linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to\n",
            "Keyword: devops engineer\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 2 - 4 minutes\n",
            "Transcription: learn networking Concepts networking is all about how computers communicate with each other think IP addresses and protocols you need to understand how data moves around secured and troubleshoot network issues to get hands-on experience I recommend using Wireshark dedicate around 2 weeks on this make sure to learn Concepts like OSI and tcpip models IP addressing and subnetting DNS and DHCP networking protocols like HTTP https FTP and SSH firewalls and security groups and basic Network troubleshooting using tools like pink trace route now let's talk about get is a version control system that lets you track changes in your code and collaborate with others it's essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like commitment for branching and merging resulting merch\n",
            "Keyword: learn networking\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 4 - 6 minutes\n",
            "Transcription: play working with remote repositories and so on after that you should dive into programming languages programming languages like python Ruby and go are used to automate tasks and manage configurations while there are several other languages I personally recommend python for its Simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in Python make sure to Learn Python syntax and data structures like lists dictionaries sets on topples modules and packages learn how to write and execute Python scripts work with files handle errors write automation scripts and so on by the way to help you on this journey of created a free supplementary PDF that breaks down the specific Concepts you need to learn for each skill it's a great resource to review your progress find gaps in your knowledge and prepare for interviews you can find the link in the description box also I have a bunch of tutorials on this channel and complete courses on my website if you're looking for structured learning\n",
            "Keyword: learn python\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 6 - 8 minutes\n",
            "Transcription: let's talk about Cloud providers Cloud providers like AWS Azure and Google Cloud platform offer a range of services for building and deploying applications if you're just starting out I recommend focusing on one cloud provider and AWS is a great choice because it's the most widely used spent about 4 to 6 weeks on this make sure to learn how to launch configure and manage virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is containerization containerization is all about packaging an application and it's dependencies into a container to ensure it runs the same everywhere Docker is the go to tool for this spam about 3 to 4 weeks getting comfortable with Docker learn how to create Docker images get familiar with starting stopping and managing containers learn how to write Docker files Explorer how to define and run\n",
            "Keyword: cloud platform\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 8 - 10 minutes\n",
            "Transcription: multi container applications using Docker compose and so on now let's dive into continuous integration and deployment or cicd cicd Artemis the integration and deployment of code changes allowing for frequent and reliable releases Jenkins is a powerful tool for setting up Ci City pipelines but other popular tools include gitlab cicd Circle C i and Travis CI if you're starting out just focus on Jenkins for its versatility and strong Community Support dedicate three to four weeks on this make sure to understand how to create and manage Jenkins pipelines get familiar with writing Jenkins files learn how to integrate automated tests into your pipelines understand how to automate the build process for your applications Explorer how to automate the deployment of your applications to various environments and Swan moving forward let's discuss orchestration and management orchestration tools like kubernetes and Helm Health automate the deployment scaling and\n",
            "Keyword: jenkins pipelines\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 10 - 12 minutes\n",
            "Transcription: management of containerized applications these tools are essential for managing complex applications in production start with kubernetes and spend about 4 to 6 weeks on it make sure to learn about the overall architecture including the master known and worker notes and how they interact understand the key components such as Parts services and deployments get familiar with managing resources learn how to scale your applications as well as the networking model in kubernetes next we have networking and infrastructure services this involves setting up and managing services like reverse proxies forward proxies cashing servers and load balances I recommend using nginx for handling reverse proxies and load balancing give this about three to four weeks of your time learn how to set up and configure engine X as a reverse proxy understand how to configure it to act as a forward proxy Explorer cashing strategies to improve the performance and how to configure firewalls and\n",
            "Keyword: kubernetes\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 12 - 14 minutes\n",
            "Transcription: now let's talk about configuration management configuration management tools like ansible puppet and Chef automate the deployment configuration and management of servers and applications if you're starting out just focus on ansible due to its Simplicity and Powerful features spent 3 to 4 weeks on this learn how to write ansible Play Books understand how to use roles and modules learn to manage variables and templates and so on moving on let's discuss our code or IAC I see in managing and provisioning infrastructure through machine readable configuration files popular tools include terraform AWS cloudformation and pelumi if you're starting out just focus on terraform for its flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files learn how to use terraform modules as\n",
            "Keyword: terraform configuration\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 14 - 16 minutes\n",
            "Transcription: what does advanced concepts such as workspaces and remote State finally let's talk about monitoring and logging monitoring and logging tools such as Prometheus grafana elk stack and fluently track the performance and health of your applications and infrastructure if you're starting out just focus on Prometheus and grafana spend about 3 to 4 weeks on these tools learn the architecture and data model of Prometheus get familiar with collecting metrics from various sources learn how to write queries to extract and analyze metrics data understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a devops engineer in about 10 to 14 months if you have any questions please let me know in the comments below and I'll do my best to answer you right here or in my future videos If you enjoyed this video please give it a like And subscribe for more content thanks for watching\n",
            "Keyword: devops engineer\n",
            "\n",
            "==================================================\n",
            "\n",
            "Timestamp: 16 - 18 minutes\n",
            "Transcription: Could not transcribe audio\n",
            "Keyword: None\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from keybert import KeyBERT\n",
        "import json\n",
        "import math\n",
        "\n",
        "# File path for the audio file\n",
        "audio_path = '/content/The_Complete_DevOps_Roadmap.wav'\n",
        "\n",
        "# Load the audio file using pydub\n",
        "audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "# Create KeyBERT model instance\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Load the Vosk model (make sure you have downloaded the model)\n",
        "vosk_model_path = \"/path/to/vosk-model\"  # Replace with the path to your Vosk model\n",
        "if not os.path.exists(vosk_model_path):\n",
        "    raise FileNotFoundError(f\"Vosk model not found at {vosk_model_path}\")\n",
        "model = Model(vosk_model_path)\n",
        "\n",
        "# Function to split audio into segments (2 minutes each)\n",
        "def split_audio(audio, segment_length=2 * 60 * 1000):  # 2 minutes in milliseconds\n",
        "    segments = []\n",
        "    total_duration = len(audio)\n",
        "    num_segments = math.ceil(total_duration / segment_length)\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * segment_length\n",
        "        end_time = min((i + 1) * segment_length, total_duration)\n",
        "        segment = audio[start_time:end_time]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "# Function to transcribe audio to text using Vosk\n",
        "def transcribe_audio_with_vosk(segment_path):\n",
        "    with open(segment_path, \"rb\") as f:\n",
        "        recognizer = KaldiRecognizer(model, 16000)\n",
        "        recognizer.SetWords(True)\n",
        "        while True:\n",
        "            data = f.read(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            recognizer.AcceptWaveform(data)\n",
        "        result = json.loads(recognizer.FinalResult())\n",
        "        return result.get(\"text\", \"\")\n",
        "\n",
        "# Function to extract the top keyword using KeyBERT\n",
        "def extract_top_keyword(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
        "    # Return only the top keyword (the first one with the highest score)\n",
        "    return keywords[0][0] if keywords else None\n",
        "\n",
        "# Split the audio into segments\n",
        "segments = split_audio(audio)\n",
        "\n",
        "# Timeline and segment keyword extraction\n",
        "timeline = []\n",
        "for i, segment in enumerate(segments):\n",
        "    # Export the segment to a temporary file\n",
        "    temp_segment_path = f\"/content/temp_segment_{i}.wav\"\n",
        "    segment.export(temp_segment_path, format=\"wav\")\n",
        "\n",
        "    # Transcribe the audio segment using Vosk\n",
        "    transcription = transcribe_audio_with_vosk(temp_segment_path)\n",
        "\n",
        "    if transcription:\n",
        "        # Extract the top keyword for the transcription\n",
        "        top_keyword = extract_top_keyword(transcription)\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",  # 2-minute intervals\n",
        "            \"keyword\": top_keyword,\n",
        "            \"transcription\": transcription\n",
        "        })\n",
        "    else:\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",\n",
        "            \"keyword\": None,\n",
        "            \"transcription\": \"Could not transcribe audio\"\n",
        "        })\n",
        "\n",
        "    # Clean up the temporary file\n",
        "    os.remove(temp_segment_path)\n",
        "\n",
        "# Output the timeline\n",
        "for segment in timeline:\n",
        "    print(f\"Timestamp: {segment['timestamp']}\")\n",
        "    print(f\"Transcription: {segment['transcription']}\")\n",
        "    print(f\"Keyword: {segment['keyword']}\")\n",
        "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "JD9ol-mVCqpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# Define the URL for the Vosk model\n",
        "vosk_model_url = \"https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\"\n",
        "vosk_model_path = \"/content/vosk-model-small-en-us\"\n",
        "\n",
        "# Download the model if it doesn't exist\n",
        "if not os.path.exists(vosk_model_path):\n",
        "    print(\"Downloading Vosk model...\")\n",
        "    model_zip_path = \"/content/vosk-model-small-en-us.zip\"\n",
        "    response = requests.get(vosk_model_url, stream=True)\n",
        "\n",
        "    # Save the zip file\n",
        "    with open(model_zip_path, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "    # Extract the zip file\n",
        "    print(\"Extracting the Vosk model...\")\n",
        "    with zipfile.ZipFile(model_zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"/content/\")\n",
        "    print(f\"Model extracted to {vosk_model_path}.\")\n",
        "\n",
        "    # Clean up the zip file\n",
        "    os.remove(model_zip_path)\n",
        "else:\n",
        "    print(f\"Vosk model already exists at {vosk_model_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyy8PJiDDBIW",
        "outputId": "b6766121-b7f1-4fc2-f901-90ba2b7ef62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vosk) (4.67.1)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk) (14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2024.12.14)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=33b62a8530b50d8797ebc988e9961059643c521179e1097ea02ab2e706e8e434\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/43/f1/23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
            "Successfully built srt\n",
            "Installing collected packages: srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45\n",
            "Downloading Vosk model...\n",
            "Download complete.\n",
            "Extracting the Vosk model...\n",
            "Model extracted to /content/vosk-model-small-en-us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub keybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoRX4CkqDS_Z",
        "outputId": "82917b66-0b5d-4be6-9fd7-f70fedab1164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.0)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.12.14)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: pydub, keybert\n",
            "Successfully installed keybert-0.8.5 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from keybert import KeyBERT\n",
        "import json\n",
        "import math\n",
        "\n",
        "# File path for the audio file\n",
        "audio_path = '/content/The_Complete_DevOps_Roadmap.wav'\n",
        "\n",
        "# Load the audio file using pydub\n",
        "audio = AudioSegment.from_wav(audio_path)\n",
        "\n",
        "# Create KeyBERT model instance\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Load the Vosk model (make sure you have downloaded the model)\n",
        "vosk_model_path = \"/content/vosk-model-small-en-us-0.15\"  # Replace with the path to your Vosk model\n",
        "if not os.path.exists(vosk_model_path):\n",
        "    raise FileNotFoundError(f\"Vosk model not found at {vosk_model_path}\")\n",
        "model = Model(vosk_model_path)\n",
        "\n",
        "# Function to split audio into segments (2 minutes each)\n",
        "def split_audio(audio, segment_length= 60 * 1000):  # 2 minutes in milliseconds\n",
        "    segments = []\n",
        "    total_duration = len(audio)\n",
        "    num_segments = math.ceil(total_duration / segment_length)\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * segment_length\n",
        "        end_time = min((i + 1) * segment_length, total_duration)\n",
        "        segment = audio[start_time:end_time]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "# Function to transcribe audio to text using Vosk\n",
        "def transcribe_audio_with_vosk(segment_path):\n",
        "    with open(segment_path, \"rb\") as f:\n",
        "        recognizer = KaldiRecognizer(model, 16000)\n",
        "        recognizer.SetWords(True)\n",
        "        while True:\n",
        "            data = f.read(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            recognizer.AcceptWaveform(data)\n",
        "        result = json.loads(recognizer.FinalResult())\n",
        "        return result.get(\"text\", \"\")\n",
        "\n",
        "# Function to extract the top keyword using KeyBERT\n",
        "def extract_top_keyword(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
        "    # Return only the top keyword (the first one with the highest score)\n",
        "    return keywords[0][0] if keywords else None\n",
        "\n",
        "# Split the audio into segments\n",
        "segments = split_audio(audio)\n",
        "\n",
        "# Timeline and segment keyword extraction\n",
        "timeline = []\n",
        "for i, segment in enumerate(segments):\n",
        "    # Export the segment to a temporary file\n",
        "    temp_segment_path = f\"/content/temp_segment_{i}.wav\"\n",
        "    segment.export(temp_segment_path, format=\"wav\")\n",
        "\n",
        "    # Transcribe the audio segment using Vosk\n",
        "    transcription = transcribe_audio_with_vosk(temp_segment_path)\n",
        "\n",
        "    if transcription:\n",
        "        # Extract the top keyword for the transcription\n",
        "        top_keyword = extract_top_keyword(transcription)\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",  # 2-minute intervals\n",
        "            \"keyword\": top_keyword,\n",
        "            \"transcription\": transcription\n",
        "        })\n",
        "    else:\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",\n",
        "            \"keyword\": None,\n",
        "            \"transcription\": \"Could not transcribe audio\"\n",
        "        })\n",
        "\n",
        "    # Clean up the temporary file\n",
        "    os.remove(temp_segment_path)\n",
        "\n",
        "# Output the timeline\n",
        "for segment in timeline:\n",
        "    print(f\"Timestamp: {segment['timestamp']}\")\n",
        "    print(f\"Transcription: {segment['transcription']}\")\n",
        "    print(f\"Keyword: {segment['keyword']}\")\n",
        "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812,
          "referenced_widgets": [
            "f588edd33c5e49b6bf1d56d4e2ef6588",
            "ab87b72eebc841c1b39de8b0ded991de",
            "04a4c16f0dd247969f2b163b401f45b7",
            "8bdbc472081046c2925e1081200114ce",
            "27d5940878c04be6bc17215bda97bf97",
            "857ce78359bf4d379774b064c1c250ef",
            "4e6f932cddad4676ae937e225924468a",
            "ae83d405f7e54c369d9e225ce7587d39",
            "3f75a21ff6a248dfaf2535df57e184d2",
            "1efa80263db04aef99fd6852e476dc11",
            "c66280dde41f4fcc99c5982ec5c42655",
            "673677cbbfde40f3b087aad3d21eef14",
            "538c7118abf249919332577948409ef6",
            "2c822c67003d45c0bd8842227a9fbec8",
            "34d5c1aa0c5d4642a4127656987d6432",
            "3dcc7372f6cd4d419e9b1fc30675f98f",
            "631c60e528564a08bba06ea1e83157c9",
            "01eb1735409b4571a6b034a08f59b905",
            "2a5a455c41784c7e96355acd2ce2a9b9",
            "a85c9364370740c0b0eb71911a7ae7ed",
            "12a79420448742c991879ee149cd0ab1",
            "01176bc613f14134ae88f65c1af407d2",
            "f4ab7d6c936e4baab9480a01b22da05d",
            "08f4b57dbec543409ce33ec54d9ed8c1",
            "5a09da14798543908720db8f48e714f2",
            "998b7880e2b14420adce6744e0f20ea9",
            "ab0ff017b75a4c95babf931a9b7c7d63",
            "bd48e486705e4db680ed655295e5053f",
            "474ad3ab9f444961849009424429451d",
            "70e3a80ef0c342f896eee88d22fa7441",
            "2d9f8b08fe784c72aa49105d1ba15971",
            "2c116284bf134c3591df36b7d6506775",
            "43ce4498d99943cd996898fddff77f4e",
            "a2fd7d1760ca4d6b9a21e37da9604720",
            "278bf424a7a24383af7cd06890412382",
            "1afc47886c254ca193ac18d775f428e3",
            "beccde9fa2f7492995df66c417cfa853",
            "94f35e7a169d4ac2b2ccfa4a40a34482",
            "2c4557be61824696bbeb040ac5a46223",
            "f9888d33ef424e58b04a8dbda1936756",
            "c1b6cc247b77480284b9a0829c880040",
            "3afadc89ad5643a0aa8b1e9c42e89cdc",
            "115230a817c44bc983fc298308ce282c",
            "8120abcb54cf41a090fd2ba02c4d7aff",
            "9d8b788c69044cd8b71e802df468880f",
            "42e0639c01e240debc1d116e6b359a2c",
            "5c7b36e005444df48cb474c37246c4cf",
            "5ae5887fd7ea4d7383ea62d2b13b87cc",
            "5ddb365990bc40f8882d3979652a8fae",
            "ab7f6bf9ad614af7b4209c39183a34f7",
            "83b9e9ba049a445695e4522479cf6a41",
            "105ec57f66a34e51ab5d7e2fd5e35295",
            "c665f5317a34412ba05486046be03ff4",
            "ae4f29a92aa0488386b23eaa0c8a7c73",
            "3d8028c067fa4c4a9eda35661534c929",
            "08f0fb2483264c8d8bf3ac8626eb7a87",
            "97663bbd7ab74a9f91207b3a44284800",
            "4b994572d83344d68fbd76d654ed8b18",
            "57a36a9a7e244715b886aba05bba9a3c",
            "08d811caca004d3daf5ffc969ab5fb75",
            "694b933d116d48d3bbc17bf397e59838",
            "11eca8abf96049a1bdce46f4c5f1d866",
            "7cc47a509953483eac83117b0616e2c6",
            "5b27d00cb53b4302a937a3f3c77589af",
            "c6781b3bc9b845ef857b2ce978967ee5",
            "f59109b5913c446f9402808fdf446111",
            "11e6285ab0574cfaa5f0d96912b99596",
            "07a6b5b5d07c4f9d9247cbda1e4ea264",
            "4b564861330b45b5833e2a254e350cec",
            "9c268e8c3aed4eb59b50c2889b98b58c",
            "67322c4cd9f24bccaa6344d61fc0e086",
            "ab23aeca65a34ff8b7af2c1ceeb31cc8",
            "47db4b1176c04c559e8efa237b944ffc",
            "2d7eb87074fd45afb1a10b18ac6faa57",
            "b06d105964704b168bc1a01d38329c16",
            "8a0d30dc88d547e6944633e0336407e0",
            "1c067a6f6f114d3f9a8d151f6e6545bc",
            "d1f1a37da5ca4f88be6bdfc0d2a7a1d1",
            "b3b93e50024e4bcab56e634ace9b7c1c",
            "1e4b3e524d664590b2f9dcddf2a6674a",
            "0542752feaaa4e2aae91653b3daee94d",
            "bf7d63e49c3b4057a536a111d765513b",
            "30feff0c713d472681a8bda4e11121ae",
            "2120e51669e043c8862a67bd282b5018",
            "560c000c8a594ce38290e57fb79c91b5",
            "2e13af3e8ad5491b9590dbb70b8fb1f9",
            "d0adc63c2b4c4b2d8a562716fd2cea97",
            "c14a2270418644528a984223d68479cb",
            "ac4efd2bd4c84080a9fcf9788063e59c",
            "18c12a03286c49fdaaa0b3891490146a",
            "24b952c2008f4b008d027e17b4845944",
            "b19a277ed4094a8cabe7f0961c6e2adf",
            "a75d3d8c07e54a87be8517d8f30eaa1d",
            "8629fc13f2594eb99c9077569f0ebf41",
            "af4162d2c2e84545bf67316412d136bc",
            "64cb504e09334dd4a692545beffe5bdc",
            "c0be5a8fbddc4578836c92e0d11987b2",
            "2b851afdcdec478b9563b83c217c7433",
            "07add51f44ce48eda6311060983f6ec4",
            "aae6553b04b5496c8921ed8c7cf222c8",
            "42a264c6bc81436fb645c5ec60a2b505",
            "f43ac47d50d24604b7598320a976cfe6",
            "7f3a177ec51f41e69fda990086da88fc",
            "f6792efeccbd4c6d9f781dc9c989cb0b",
            "443b3d998ef44501806adea909f3856f",
            "db472ab4f8c94565b8280943d77793a0",
            "4121f4023f5744948c4a9df42d866567",
            "8bcc4bb3024f4a15a29fb3c0781ad77b",
            "235cfc0134004522974f1d5357f00b1e",
            "0446e0cceb434093b881b390fc25f514",
            "bd4d2eb834344430a5017319b673febf",
            "c9f4598cb5bb452b9e6dd972cb5773e6",
            "43a4cf85b77b4f25b85ee928a17afc33",
            "f227f5a92f8744368532058e38f3d698",
            "6d3c4b5d065b4625992109a2116227a6",
            "6327f6b28cbb4439abb7f24864b398a7",
            "11078da9c5c640d29afbbd0ba1d15e68",
            "d458e170993d4933a742cab642336458",
            "78efd476af644681874666cc89d815ff",
            "f87e4227155b47b1b4a1654434cbbe7c",
            "21232b2962be4dc0a1bb77a1ecd2ef72"
          ]
        },
        "id": "ohtKAVKNC-54",
        "outputId": "4a468bbe-98b3-4aa2-855a-ca1679da98c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f588edd33c5e49b6bf1d56d4e2ef6588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "673677cbbfde40f3b087aad3d21eef14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ab7d6c936e4baab9480a01b22da05d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2fd7d1760ca4d6b9a21e37da9604720"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d8b788c69044cd8b71e802df468880f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08f0fb2483264c8d8bf3ac8626eb7a87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11e6285ab0574cfaa5f0d96912b99596"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1f1a37da5ca4f88be6bdfc0d2a7a1d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac4efd2bd4c84080a9fcf9788063e59c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aae6553b04b5496c8921ed8c7cf222c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd4d2eb834344430a5017319b673febf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e091297848e5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Transcribe the audio segment using Vosk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio_with_vosk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_segment_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtranscription\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e091297848e5>\u001b[0m in \u001b[0;36mtranscribe_audio_with_vosk\u001b[0;34m(segment_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAcceptWaveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFinalResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vosk/__init__.py\u001b[0m in \u001b[0;36mAcceptWaveform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mAcceptWaveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvosk_recognizer_accept_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to process waveform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install speech_recognition"
      ],
      "metadata": {
        "id": "LHGGhmBjGgNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "from keybert import KeyBERT\n",
        "import math\n",
        "\n",
        "# File path for the audio file\n",
        "audio_path = '/content/The_Complete_DevOps_Roadmap.wav'\n",
        "\n",
        "# Load the audio file using pydub\n",
        "audio = AudioSegment.from_mp3(audio_path)\n",
        "\n",
        "# Create the recognizer for speech-to-text\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Create KeyBERT model instance\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Function to split audio into segments (2 minutes each)\n",
        "def split_audio(audio, segment_length= 60 * 1000):  # 2 minutes in milliseconds\n",
        "    segments = []\n",
        "    total_duration = len(audio)\n",
        "    num_segments = math.ceil(total_duration / segment_length)\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * segment_length\n",
        "        end_time = min((i + 1) * segment_length, total_duration)\n",
        "        segment = audio[start_time:end_time]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "# Function to transcribe audio to text using Google Speech Recognition\n",
        "def transcribe_audio(segment):\n",
        "    with sr.AudioFile(segment) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            return None\n",
        "        except sr.RequestError:\n",
        "            return None\n",
        "\n",
        "# Function to extract the top keyword using KeyBERT\n",
        "def extract_top_keyword(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english')\n",
        "    # Return only the top keyword (the first one with the highest score)\n",
        "    return keywords[0][0] if keywords else None\n",
        "\n",
        "# Split the audio into segments\n",
        "segments = split_audio(audio)\n",
        "\n",
        "# Timeline and segment keyword extraction\n",
        "timeline = []\n",
        "for i, segment in enumerate(segments):\n",
        "    # Export the segment to a temporary file\n",
        "    temp_segment_path = f\"/content/temp_segment_{i}.wav\"\n",
        "    segment.export(temp_segment_path, format=\"wav\")\n",
        "\n",
        "    # Transcribe the audio segment\n",
        "    transcription = transcribe_audio(temp_segment_path)\n",
        "\n",
        "    if transcription:\n",
        "        # Extract the top keyword for the transcription\n",
        "        top_keyword = extract_top_keyword(transcription)\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",  # 2-minute intervals\n",
        "            \"keyword\": top_keyword,\n",
        "            \"transcription\": transcription\n",
        "        })\n",
        "    else:\n",
        "        timeline.append({\n",
        "            \"timestamp\": f\"{i * 2} - {(i + 1) * 2} minutes\",\n",
        "            \"keyword\": None,\n",
        "            \"transcription\": \"Could not transcribe audio\"\n",
        "        })\n",
        "\n",
        "    # Clean up the temporary file\n",
        "    os.remove(temp_segment_path)\n",
        "\n",
        "# Output the timeline\n",
        "for segment in timeline:\n",
        "    print(f\"Timestamp: {segment['timestamp']}\")\n",
        "    print(f\"Transcription: {segment['transcription']}\")\n",
        "    print(f\"Keyword: {segment['keyword']}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "Qj8sC24MGaSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1min late\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Path to the audio file\n",
        "audio_file_path = \"/content/The_Complete_DevOps_Roadmap.mp3\"\n",
        "\n",
        "# Convert MP3 to WAV (required by the library)\n",
        "print(\"Converting MP3 to WAV...\")\n",
        "audio = AudioSegment.from_mp3(audio_file_path)\n",
        "wav_path = \"/content/The_Complete_DevOps_Roadmap.wav\"\n",
        "audio.export(wav_path, format=\"wav\")\n",
        "print(\"Conversion complete.\")\n",
        "\n",
        "# Split the audio into 1-minute chunks\n",
        "chunk_length_ms = 60000  # 1 minute\n",
        "print(\"Splitting the audio into chunks...\")\n",
        "chunks = make_chunks(audio, chunk_length_ms)\n",
        "\n",
        "# Transcribe each chunk\n",
        "transcription = \"\"\n",
        "for i, chunk in enumerate(chunks):\n",
        "    chunk_name = f\"/content/chunk_{i}.wav\"\n",
        "    chunk.export(chunk_name, format=\"wav\")  # Export chunk\n",
        "    print(f\"Processing chunk {i + 1}/{len(chunks)}: {chunk_name}\")\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(chunk_name) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            chunk_transcription = recognizer.recognize_google(audio_data)\n",
        "            transcription += f\"\\n[Chunk {i + 1}]\\n{chunk_transcription}\\n\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing chunk {i + 1}: {str(e)}\")\n",
        "        transcription += f\"\\n[Chunk {i + 1}]\\nError in transcription\\n\"\n",
        "\n",
        "# Output the complete transcription\n",
        "print(\"Complete Transcription:\\n\")\n",
        "print(transcription)\n",
        "\n",
        "# Save the transcription to a file\n",
        "transcription_file = \"/content/transcription.txt\"\n",
        "with open(transcription_file, \"w\") as file:\n",
        "    file.write(transcription)\n",
        "\n",
        "print(f\"Transcription saved to {transcription_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwIzhYr0f4xk",
        "outputId": "f6eb43eb-43fa-425e-b39a-a9ba0d895098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting MP3 to WAV...\n",
            "Conversion complete.\n",
            "Splitting the audio into chunks...\n",
            "Processing chunk 1/9: /content/chunk_0.wav\n",
            "Processing chunk 2/9: /content/chunk_1.wav\n",
            "Processing chunk 3/9: /content/chunk_2.wav\n",
            "Processing chunk 4/9: /content/chunk_3.wav\n",
            "Processing chunk 5/9: /content/chunk_4.wav\n",
            "Processing chunk 6/9: /content/chunk_5.wav\n",
            "Processing chunk 7/9: /content/chunk_6.wav\n",
            "Processing chunk 8/9: /content/chunk_7.wav\n",
            "Processing chunk 9/9: /content/chunk_8.wav\n",
            "Error transcribing chunk 9: \n",
            "Complete Transcription:\n",
            "\n",
            "\n",
            "[Chunk 1]\n",
            "if you're looking to break into devops or want to level up your skills you're in the right place today I'm sharing the complete devops roadmap I'll walk you through the essential skills you need the tools I personally recommend and how much time you should spend on each assuming you're dedicate three to five hours of studying everyday this road map should take you about 10 to 14 months to complete let's Jump Right In first off we have Linux fundamentals Linux is the background of servers and development environments as a devops engineer you'll be setting up and maintaining the infrastructure where applications run most servers use Linux so getting comfortable with it especially the command line is crucial I recommend starting with learning bash which is the most commonly used shell and scripting language in Linux spend about two to three weeks on this make sure to learn basic Linux commands for working with the file system permissions and ownership processes and signals as well as managing packages next you need to\n",
            "\n",
            "[Chunk 2]\n",
            "learn networking Concepts networking is all about how computers communicate with each other think IP addresses and protocols you need to understand how data moves around secured and troubleshoot network issues to get hands-on experience I recommend using Wireshark dedicate around 2 weeks on this make sure to learn Concepts like OSI and tcpip models IP addressing and subnetting DNS and DHCP networking protocols like HTTP https FTP and SSH firewalls and security groups and basic Network troubleshooting using tools like pink trace route now let's talk about get is a version control system that lets you track changes in your code and collaborate with others it's essential for working on projects with a team and managing your code effectively spend one to two weeks getting comfortable with get make sure to learn basic get commands like commitment for branching and merging resulting merch\n",
            "\n",
            "[Chunk 3]\n",
            "play working with remote repositories and so on after that you should dive into programming languages programming languages like python Ruby and go are used to automate tasks and manage configurations while there are several other languages I personally recommend python for its Simplicity powerful libraries and versatility dedicate four to six weeks to build a solid foundation in Python make sure to Learn Python syntax and data structures like lists dictionaries sets on topples modules and packages learn how to write and execute Python scripts work with files handle errors write automation scripts and so on by the way to help you on this journey of created a free supplementary PDF that breaks down the specific Concepts you need to learn for each skill it's a great resource to review your progress find gaps in your knowledge and prepare for interviews you can find the link in the description box also I have a bunch of tutorials on this channel and complete courses on my website if you're looking for structured learning\n",
            "\n",
            "[Chunk 4]\n",
            "let's talk about Cloud providers Cloud providers like AWS Azure and Google Cloud platform offer a range of services for building and deploying applications if you're just starting out I recommend focusing on one cloud provider and AWS is a great choice because it's the most widely used spent about 4 to 6 weeks on this make sure to learn how to launch configure and manage virtual servers store and manage data get familiar with managing users groups and roles and how to set up and manage isolated networks next up is containerization containerization is all about packaging an application and it's dependencies into a container to ensure it runs the same everywhere Docker is the go to tool for this spam about 3 to 4 weeks getting comfortable with Docker learn how to create Docker images get familiar with starting stopping and managing containers learn how to write Docker files Explorer how to define and run\n",
            "\n",
            "[Chunk 5]\n",
            "multi container applications using Docker compose and so on now let's dive into continuous integration and deployment or cicd cicd Artemis the integration and deployment of code changes allowing for frequent and reliable releases Jenkins is a powerful tool for setting up Ci City pipelines but other popular tools include gitlab cicd Circle C i and Travis CI if you're starting out just focus on Jenkins for its versatility and strong Community Support dedicate three to four weeks on this make sure to understand how to create and manage Jenkins pipelines get familiar with writing Jenkins files learn how to integrate automated tests into your pipelines understand how to automate the build process for your applications Explorer how to automate the deployment of your applications to various environments and Swan moving forward let's discuss orchestration and management orchestration tools like kubernetes and Helm Health automate the deployment scaling and\n",
            "\n",
            "[Chunk 6]\n",
            "management of containerized applications these tools are essential for managing complex applications in production start with kubernetes and spend about 4 to 6 weeks on it make sure to learn about the overall architecture including the master known and worker notes and how they interact understand the key components such as Parts services and deployments get familiar with managing resources learn how to scale your applications as well as the networking model in kubernetes next we have networking and infrastructure services this involves setting up and managing services like reverse proxies forward proxies cashing servers and load balances I recommend using nginx for handling reverse proxies and load balancing give this about three to four weeks of your time learn how to set up and configure engine X as a reverse proxy understand how to configure it to act as a forward proxy Explorer cashing strategies to improve the performance and how to configure firewalls and\n",
            "\n",
            "[Chunk 7]\n",
            "now let's talk about configuration management configuration management tools like ansible puppet and Chef automate the deployment configuration and management of servers and applications if you're starting out just focus on ansible due to its Simplicity and Powerful features spent 3 to 4 weeks on this learn how to write ansible Play Books understand how to use roles and modules learn to manage variables and templates and so on moving on let's discuss our code or IAC I see in managing and provisioning infrastructure through machine readable configuration files popular tools include terraform AWS cloudformation and pelumi if you're starting out just focus on terraform for its flexibility and widespread use dedicate three to four weeks to build a solid foundation in terraform understand the basic concepts like providers and resources get familiar with writing terraform configuration files learn how to use terraform modules as\n",
            "\n",
            "[Chunk 8]\n",
            "what does advanced concepts such as workspaces and remote State finally let's talk about monitoring and logging monitoring and logging tools such as Prometheus grafana elk stack and fluently track the performance and health of your applications and infrastructure if you're starting out just focus on Prometheus and grafana spend about 3 to 4 weeks on these tools learn the architecture and data model of Prometheus get familiar with collecting metrics from various sources learn how to write queries to extract and analyze metrics data understand how to set up alerts and so on so if you dedicate three to five hours every day you can follow this road map and pick up all the skills you need to become a devops engineer in about 10 to 14 months if you have any questions please let me know in the comments below and I'll do my best to answer you right here or in my future videos If you enjoyed this video please give it a like And subscribe for more content thanks for watching\n",
            "\n",
            "[Chunk 9]\n",
            "Error in transcription\n",
            "\n",
            "Transcription saved to /content/transcription.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUrtxJ-7oUyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JEj2AfdoU0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Set your OpenAI API Key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    \"\"\"\n",
        "    Chat endpoint to process user input and generate a response.\n",
        "    \"\"\"\n",
        "    user_message = request.json.get(\"message\", \"\")\n",
        "    if not user_message:\n",
        "        return jsonify({\"error\": \"Message is required\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Generate GPT response\n",
        "        response = get_gpt_response(user_message)\n",
        "        return jsonify({\"response\": response})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "def get_gpt_response(question):\n",
        "    \"\"\"\n",
        "    Generates a GPT response that simulates searching the web for answers.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a knowledgeable assistant with access to web search capabilities. A user has asked the following question:\n",
        "\n",
        "    \"{question}\"\n",
        "\n",
        "    Please provide a detailed and accurate answer as if you searched the web. Include relevant sources (even if hypothetical) to back up your response. Clearly list these sources at the end.\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and factual assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,  # Controls creativity (lower = more focused, higher = more creative)\n",
        "    )\n",
        "\n",
        "    # Extract the generated response\n",
        "    answer = response['choices'][0]['message']['content']\n",
        "    return answer\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vDQ4okCoU4G",
        "outputId": "2a9dcca5-5430-4f19-a149-467fe5c4b5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install OpenAI library if not already installed\n",
        "!pip install openai\n",
        "\n",
        "# Import required library\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def gpt_chatbot(question):\n",
        "    \"\"\"\n",
        "    Simulates a chatbot that searches the web and provides an answer with sources.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a knowledgeable assistant with access to web search capabilities. A user has asked the following question:\n",
        "\n",
        "    \"{question}\"\n",
        "\n",
        "    Please provide a detailed and accurate answer as if you searched the web. Include relevant sources (even if hypothetical) to back up your response. Clearly list these sources at the end.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Generate a response using the OpenAI GPT API\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful and factual assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,  # Controls creativity\n",
        "        )\n",
        "        answer = response['choices'][0]['message']['content']\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Example usage\n",
        "user_question = \"Is solar energy renewable? answer just saying yes or no\"\n",
        "response = gpt_chatbot(user_question)\n",
        "print(\"Chatbot Response:\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHWmABjTpZDI",
        "outputId": "3f969f71-2e86-4e84-9cae-70aebdc2989b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Chatbot Response:\n",
            "An error occurred: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest version of OpenAI library\n",
        "!pip install --upgrade openai\n",
        "\n",
        "# Import required library\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def gpt_chatbot(question):\n",
        "    \"\"\"\n",
        "    Simulates a chatbot that searches the web and provides an answer with sources.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a knowledgeable assistant with access to web search capabilities. A user has asked the following question:\n",
        "\n",
        "    \"{question}\"\n",
        "\n",
        "    Please provide a detailed and accurate answer as if you searched the web. Include relevant sources (even if hypothetical) to back up your response. Clearly list these sources at the end.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Generate a response using the OpenAI GPT API\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful and factual assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,  # Controls creativity\n",
        "        )\n",
        "        return response.choices[0].message[\"content\"]\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Example usage\n",
        "user_question = \"Is solar energy renewable? answer just saying yes or no\"\n",
        "response = gpt_chatbot(user_question)\n",
        "print(\"Chatbot Response:\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7EiCuFupuSE",
        "outputId": "8bbc9d62-b42c-447c-de80-c343393ee22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Collecting openai\n",
            "  Downloading openai-1.59.9-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.59.9-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.5/455.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.6\n",
            "    Uninstalling openai-1.59.6:\n",
            "      Successfully uninstalled openai-1.59.6\n",
            "Successfully installed openai-1.59.9\n",
            "Chatbot Response:\n",
            "An error occurred: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "def gpt_chatbot(question):\n",
        "    \"\"\"\n",
        "    Simulates a chatbot that searches the web and provides an answer with sources.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a knowledgeable assistant with access to web search capabilities. A user has asked the following question:\n",
        "\n",
        "    \"{question}\"\n",
        "\n",
        "    Please provide a detailed and accurate answer as if you searched the web. Include relevant sources (even if hypothetical) to back up your response. Clearly list these sources at the end.\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and factual assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "user_question = \"is solar energy a renewable energy? answer yes or no\"\n",
        "response = gpt_chatbot(user_question)\n",
        "print(\"Chatbot Response:\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekuSM-x3qEoC",
        "outputId": "5ab9f942-210f-4b61-e671-fe82131f8d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot Response:\n",
            "Yes, solar energy is considered a renewable energy source. Renewable energy sources are those that are naturally replenished and are virtually inexhaustible over human timescales. Solar energy is derived from the sun's radiation and is constantly being replenished. It is a sustainable and clean source of energy that can be utilized through technologies such as solar panels to generate electricity or heat.\n",
            "\n",
            "Sources:\n",
            "- U.S. Department of Energy: https://www.energy.gov/eere/solar/solar-energy\n",
            "- National Renewable Energy Laboratory (NREL): https://www.nrel.gov/research/re-solar.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.27.8\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "acpLj0rKqQGw",
        "outputId": "578f7773-7fb6-41dc-f76c-53e54eda3fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.27.8) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.27.8) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.27.8) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.27.8) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.27.8) (1.18.3)\n",
            "Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.9\n",
            "    Uninstalling openai-1.59.9:\n",
            "      Successfully uninstalled openai-1.59.9\n",
            "Successfully installed openai-0.27.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "e60ac45833e54dee8afbdc875433bb24"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}